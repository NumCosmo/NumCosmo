{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da058759-7eb2-463b-8d8a-f1f249308afb",
   "metadata": {},
   "source": [
    "# ESMCMC: Richness-Mass Scaling Relation Calibration\n",
    "\n",
    "---\n",
    "**License**\n",
    "\n",
    " ESMCMC_RM_SR_Models\n",
    "\n",
    " Mon Nov 11 10:30:00 2024\\\n",
    " Copyright  2024\\\n",
    " Cinthia Nunes de Lima <cinthia.n.lima@uel.br> \\ Sandro Dias Pinto Vitenti <vitenti@uel.br>\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    " ESMCMC_RM_SR_Models\\\n",
    " Copyright (C) 2024 Cinthia Nunes de Lima <cinthia.n.lima@uel.br>, Sandro Dias Pinto Vitenti <vitenti@uel.br>\n",
    "\n",
    " numcosmo is free software: you can redistribute it and/or modify it\n",
    " under the terms of the GNU General Public License as published by the\n",
    " Free Software Foundation, either version 3 of the License, or\n",
    " (at your option) any later version.\n",
    "\n",
    " numcosmo is distributed in the hope that it will be useful, but\n",
    " WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    " MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
    " See the GNU General Public License for more details.\n",
    "\n",
    " You should have received a copy of the GNU General Public License along\n",
    " with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbff4ee-2caf-49f6-8725-b0ebd29b42d7",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f9b466-a941-4db1-b09f-e69d9320f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.insert(0, \"/global/homes/c/cinlima/NumCosmo/notebooks/richness_proxy/\")\n",
    "#sys.path.insert(0, \"/global/homes/c/cinlima/NumCosmo/notebooks/richness_proxy/ESMCMC\")\n",
    "\n",
    "sys.path.insert(0, \"/global/homes/l/lettieri/NumCosmo/notebooks/richness_proxy/\")\n",
    "sys.path.insert(0, \"/global/homes/l/lettieri/NumCosmo/notebooks/richness_proxy/ESMCMC\")\n",
    "\n",
    "\n",
    "from esmcmc_rm_relation_script import catalog_fit, esmcmc\n",
    "\n",
    "#NumCosmo\n",
    "from numcosmo_py import Ncm, Nc, GObject\n",
    "Ncm.cfg_init()\n",
    "Ncm.cfg_set_log_handler(lambda msg: sys.stdout.write(msg) and sys.stdout.flush())\n",
    "\n",
    "#Useful packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "#GCR Catalogs\n",
    "#sys.path.insert(0, \"/global/homes/c/cinlima/gcr-catalogs\")\n",
    "sys.path.insert(0, \"/global/homes/l/lettieri/gcr-catalogs\")\n",
    "import GCRCatalogs\n",
    "GCRCatalogs.set_root_dir_by_site(\"nersc\")\n",
    "\n",
    "#Corner plots \n",
    "from getdist import plots\n",
    "from getdist.mcsamples import  MCSamples\n",
    "import getdist\n",
    "print('GetDist Version: %s, Matplotlib version: %s'%(getdist.__version__, plt.matplotlib.__version__))\n",
    "\n",
    "import pygtc\n",
    "from IPython.display import display, Math\n",
    "%matplotlib inline\n",
    "\n",
    "from numcosmo_py.plotting.tools import set_rc_params_article      # imports Numcosmo plotting tools\n",
    "set_rc_params_article(ncol=1)\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa326bfd-ec9c-44c0-a7c8-1407cf75a634",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63422873-87c4-4fae-8e14-01bd3625505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RICH_CUT = 5\n",
    "MASS_CUT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5928494-5fe6-4e62-99eb-90ec9f3c3525",
   "metadata": {},
   "outputs": [],
   "source": [
    "cDC2 = Table.read('/global/homes/l/lettieri/NumCosmo/notebooks/richness_proxy/CatalogsMatching/match_ID.fits').to_pandas()\n",
    "#cDC2 = Table.read('/global/homes/c/cinlima/NumCosmo/notebooks/richness_proxy/CatalogsMatching/match_ID.fits').to_pandas()\n",
    "\n",
    "rich_data = cDC2[\"richness\"]\n",
    "z_data = cDC2[\"redshift\"]\n",
    "mass_data = cDC2[\"halo_mass\"]\n",
    "\n",
    "cDC2_data = Table([mass_data, rich_data, z_data], names=('mass', 'richness', 'redshift'))\n",
    "rich_data\n",
    "#Data cut:\n",
    "cDC2_data = cDC2_data[cDC2_data['richness'] > RICH_CUT]\n",
    "cDC2_data = cDC2_data[cDC2_data['mass'] > MASS_CUT]\n",
    "# cDC2_data = cDC2_data[cDC2_data['redshift'] < 0.3]\n",
    "\n",
    "print(f'Catalog info:\\nCatalog size: {len(rich_data)}\\nRichness: min: {min( rich_data):.2f}; max: {max(rich_data):.2f}.\\nRedshift: min: {min( z_data):.2f}; max: {max(z_data):.2f}.\\nMass: min: {min( mass_data):.2}; max: {max(mass_data):.2}.\\n')\n",
    "\n",
    "richness_dt = cDC2_data['richness']\n",
    "mass_dt = cDC2_data['mass']\n",
    "\n",
    "print(f'Cut data:\\nCatalog size: {len(cDC2_data)}.\\nRichness: min: {min(richness_dt):.2f}; max: {max(richness_dt):.2f}\\nMass: min: {min( mass_dt):.2}; max: {max(mass_dt):.2}.')\n",
    "\n",
    "plt.scatter(np.log10(mass_dt), np.log(richness_dt))\n",
    "plt.axline((13, np.log(35)), (15, np.log(35)), c = 'k', ls= '--')\n",
    "plt.axvline(x = np.log10(1e14), color = 'k', ls= '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cc3cee-e0e2-4361-918a-606f7ff46a49",
   "metadata": {},
   "source": [
    "## Quadratic Model MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d38a44-21f3-4d83-acf7-a75a1d2aed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_WALKERS = 1200\n",
    "# N_RUN = 300\n",
    "# MODEL = 'ext'\n",
    "# FILE_NAME = \"full_data_set_mcmc/\"+MODEL+\".fits\"\n",
    "\n",
    "# esmcmc(cDC2_data, RICH_CUT, N_WALKERS, N_RUN, MODEL, FILE_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b576e4-7e89-4812-87a4-609946c8ca27",
   "metadata": {},
   "source": [
    "## Linear Model MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62efc45c-0c65-4388-b36c-82112079b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WALKERS = 1200\n",
    "N_RUN = 300\n",
    "MODEL2 = 'asc_without_corretion'\n",
    "#FILE_NAME2 =\"/global/homes/c/cinlima/ESMCMC/full_data_set_mcmc/\"+MODEL2+\".fits\"\n",
    "FILE_NAME2 =\"/global/homes/l/lettieri/ESMCMC/full_data_set_mcmc/\"+MODEL2+\".fits\"\n",
    "\n",
    "esmcmc(cDC2_data, RICH_CUT, N_WALKERS, N_RUN, 'asc', FILE_NAME2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaefd9a-ae7f-4f4d-a958-6609e929e674",
   "metadata": {},
   "source": [
    "## Bayes Factor\n",
    "\n",
    "Given two models $M_{1}$ and $M_2$, with parameters vectors $\\theta_{1}$ and $\\theta_{2}$, for a oberved data D, the Bayes Factor is defined as (see [Kass and Raftery, 1995](https://sites.stat.washington.edu/raftery/Research/PDF/kass1995.pdf]) and [John and Narlikar, 2002](https://journals.aps.org/prd/pdf/10.1103/PhysRevD.65.043506), for more details):\n",
    "\n",
    "$$\n",
    "BF = \\frac{P(D|M_{1})}{P(D|M_{2})} =  \\frac{\\int d\\theta_{1} P(D|\\theta_{1}, M_{1}) P(\\theta_{1}, M_{1}) }{\\int d\\theta_{2} P(D|\\theta_{2}, M_{2}) P(\\theta_{2}, M_{2})}. \n",
    "$$\n",
    "\n",
    "Where, $P(D|M_{1})$ and $P(D|M_{2})$ are the likelihood and, $P(\\theta_{1}, M_{1})$ and $P(\\theta_{2}, M_{2})$ are the priors for parameters $\\theta_{1}$ and $\\theta_{2}$.\n",
    "\n",
    "\n",
    "BF interpretation, according to Kass and Raftery, 1995:\n",
    "\n",
    "$\\log_{10}$BF| BF | Strength of evidence|\n",
    "| --------: | --------: | :------- |\n",
    "|0 < $\\log_{10}$BF < 1/2| 1 < BF < 3.2  |  Not worth more than a bare mention|\n",
    "| 1/2 < $\\log_{10}$BF < 1| 3.2 < BF < 10 |  Substantial|\n",
    "| 1 < $\\log_{10}$BF < 2| 10 < BF < 100| Strong|\n",
    "| $\\log_{10}$BF > 2| BF > 100|  Decisive|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3325b50b-5699-4ff4-bf1d-579396f8028e",
   "metadata": {},
   "source": [
    "### Bayes Factor (full data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5644c100-99a9-46a1-8b11-9b60377c9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bayesian Evidence Quadratic Model:\n",
    "\n",
    "# N_WALKERS1 = 1200\n",
    "# BURNIN1 = 55\n",
    "# FILE_NAME = \"/global/homes/c/cinlima/ESMCMC/full_data_set_mcmc/ext.fits\"\n",
    "# mcat1 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME, N_WALKERS1 * BURNIN1)\n",
    "# be1, post_lnnorm_sd1 = mcat1.get_post_lnnorm()\n",
    "# # lnevol, glnvol = mcat2.get_post_lnvol(0.6827)\n",
    "# # Bayesian Evidence Linear Model:\n",
    "\n",
    "# BURNIN2 = 75\n",
    "# N_WALKERS2 = 1200\n",
    "# FILE_NAME2 = \"/global/homes/c/cinlima/ESMCMC/full_data_set_mcmc/asc.fits\"\n",
    "# mcat2 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME2, N_WALKERS2 * BURNIN2)\n",
    "# be2, post_lnnorm_sd2 = mcat2.get_post_lnnorm()\n",
    "# # lnevol, glnvol = mcat2.get_post_lnvol(0.6827)\n",
    "\n",
    "# print(f'BEQ = {be1:.3f} +/- {post_lnnorm_sd1:.3f}.\\nBEL = {be2:.3f} +/- {post_lnnorm_sd2:.3f}.\\n\\nBF = {np.exp(be1 - be2):.3e}.')\n",
    "\n",
    "\n",
    "# Bayesian Evidence Quadratic Model:\n",
    "'''\n",
    "N_WALKERS1 = 1200\n",
    "BURNIN1 = 55\n",
    "FILE_NAME = \"/global/homes/c/cinlima/ESMCMC/with_correction/asc_rmin_5_mmin_10000000000000.0.fits\"\n",
    "mcat1 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME, N_WALKERS1 * BURNIN1)\n",
    "be1, post_lnnorm_sd1 = mcat1.get_post_lnnorm()\n",
    "# lnevol, glnvol = mcat2.get_post_lnvol(0.6827)\n",
    "# Bayesian Evidence Linear Model:\n",
    "\n",
    "BURNIN2 = 75\n",
    "N_WALKERS2 = 1200\n",
    "FILE_NAME2 = \"/global/homes/c/cinlima/ESMCMC/full_data_set_mcmc/asc_without_corretion.fits\"\n",
    "mcat2 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME2, N_WALKERS2 * BURNIN2)\n",
    "be2, post_lnnorm_sd2 = mcat2.get_post_lnnorm()\n",
    "# lnevol, glnvol = mcat2.get_post_lnvol(0.6827)\n",
    "\n",
    "print(f'BEQ = {be1:.3f} +/- {post_lnnorm_sd1:.3f}.\\nBEL = {be2:.3f} +/- {post_lnnorm_sd2:.3f}.\\n\\nBF = {np.exp(be1 - be2):.3e}.')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb11f5c-c6b2-465c-af4e-4f7bc1367db5",
   "metadata": {},
   "source": [
    "BEQ - Beyesian evidence - quadratic model.\n",
    "\n",
    "BEL - Beyesian evidence - linear model.\n",
    "\n",
    "BF - Bayes factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8381dabc-f96b-4350-8425-8dfbf9b71409",
   "metadata": {},
   "source": [
    "### Analysis using mass and richness thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37434bc-aaa5-48d8-88bd-b8f024543f61",
   "metadata": {},
   "source": [
    "#### MCMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2097704-8d53-4839-9ba1-0b7b19cc3e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RICH_CUT_list = [5, 10]\n",
    "# MASS_CUT_list = [1e13, 2e13, 5e13, 8e13, 1e14]\n",
    "# # RED_CUT_list = [0.3, 0.5, 0.8, 1.2]\n",
    "\n",
    "# # cDC2 = Table.read('/global/homes/c/cinlima/NumCosmo/notebooks/richness_proxy/CatalogsMatching/match_clevar.fits').to_pandas()\n",
    "    \n",
    "# rich_data = cDC2[\"richness\"]\n",
    "# z_data = cDC2[\"redshift\"]\n",
    "# mass_data = cDC2[\"halo_mass\"]\n",
    "   \n",
    "\n",
    "# for RICH_CUT in RICH_CUT_list:\n",
    "#     for MASS_CUT in MASS_CUT_list:\n",
    "\n",
    "     \n",
    "#         cDC2_data = Table([mass_data, rich_data, z_data], names=('mass', 'richness', 'redshift'))\n",
    "        \n",
    "#         #Data cut:\n",
    "#         cDC2_data = cDC2_data[cDC2_data['richness'] > RICH_CUT]\n",
    "#         cDC2_data = cDC2_data[cDC2_data['mass'] > MASS_CUT]         \n",
    "\n",
    "#         N_WALKERS = 1200\n",
    "#         N_RUN = 300\n",
    "            \n",
    "#         MODEL2 = 'asc'\n",
    "#         FILE_NAME2 = \"/global/homes/c/cinlima/ESMCMC/dc2-redmapper-id/\"+MODEL2+\"_rmin_\"+str(RICH_CUT)+\"_mmin_\"+str(int(MASS_CUT))+\".fits\"\n",
    "    \n",
    "#         esmcmc(cDC2_data, RICH_CUT, N_WALKERS, N_RUN, MODEL2, FILE_NAME2)\n",
    "\n",
    "# for RED_CUT in RED_CUT_list:\n",
    "#     cDC2_data = Table([mass_data, rich_data, z_data], names=('mass', 'richness', 'redshift'))\n",
    "        \n",
    "#     #Data cut:\n",
    "#     cDC2_data = cDC2_data[cDC2_data['redshift'] < RED_CUT]         \n",
    "\n",
    "#     N_WALKERS = 1200\n",
    "#     N_RUN = 300\n",
    "            \n",
    "#     MODEL2 = 'asc'\n",
    "#     FILE_NAME2 = \"/global/homes/c/cinlima/ESMCMC/redshift_analysis_nocorr/\"+MODEL2+\"_zmax_\"+str(RED_CUT)+\".fits\"\n",
    "    \n",
    "#     esmcmc(cDC2_data, RICH_CUT, N_WALKERS, N_RUN, MODEL2, FILE_NAME2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c6df1-9999-497e-93c7-9590872eb649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RICH_CUT_list = [5, 10, 15, 20, 30, 40, 50]\n",
    "# MASS_CUT_list = [1e13, 2e13, 5e13, 8e13, 1e14]\n",
    "\n",
    "# bef_list = []\n",
    "# mean_ext_list = []\n",
    "\n",
    "# for mcut in MASS_CUT_list:\n",
    "\n",
    "#     # bef = pd.DataFrame(data = {'Min_Mass':[], 'Min_Richness': [], 'BEQ': [], 'BEQ Err': [], 'BEL': [], 'BEL Err': [], \n",
    "#     #                            'BF': [], 'muM2': [], 'sd_muM2': []})\n",
    "\n",
    "#     bef = pd.DataFrame(data = {'Min_Mass':[], 'Min_Richness': [],  'BEQ': [], \n",
    "#                                              'BEQ Err': [], 'BEL': [], 'BEL Err':[], \n",
    "#                                              'BF': [], 'muM2':[], 'sd_muM2': [], \n",
    "#                                              'mu0':[], 'sd_mu0': [], 'mu1':[], 'sd_mu1': [],\n",
    "#                                              'mu2':[], 'sd_mu2': []})\n",
    "\n",
    "\n",
    "#     mean_ext = []\n",
    "\n",
    "#     for rcut in RICH_CUT_list:\n",
    "        \n",
    "#         N_WALKERS = 1200\n",
    "#         N_RUN = 300\n",
    "        \n",
    "#         RICH_CUT = rcut\n",
    "#         MASS_CUT = mcut\n",
    "#         # MODEL = 'ext'\n",
    "#         # FILE_NAME1 = \"/global/homes/c/cinlima/ESMCMC/r_threshold_mcmc/\"+MODEL+\"_rmin_\"+str(RICH_CUT)+\"_mmin_\"+str(MASS_CUT)+\".fits\"   \n",
    "        \n",
    "#         # MODEL2 = 'asc'\n",
    "#         # FILE_NAME2 = \"/global/homes/c/cinlima/ESMCMC/r_threshold_mcmc/\"+MODEL2+\"_rmin_\"+str(RICH_CUT)+\"_mmin_\"+str(MASS_CUT)+\".fits\"\n",
    "\n",
    "#         MODEL1 = 'asc'\n",
    "#         FILE_NAME1 = \"/global/homes/c/cinlima/ESMCMC/r_threshold_mcmc/\"+MODEL1+\"_rmin_\"+str(RICH_CUT)+\"_mmin_\"+str(MASS_CUT)+\".fits\"   \n",
    "       \n",
    "#         MODEL2 = 'asc'\n",
    "#         FILE_NAME2 = \"/global/homes/c/cinlima/ESMCMC/without_correction/\"+MODEL2+\"_rmin_\"+str(RICH_CUT)+\"_mmin_\"+str(MASS_CUT)+\".fits\"\n",
    "\n",
    "\n",
    "#         burnin_cat1 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME1, 0.0).peek_e_mean_stats().estimate_const_break(0) + 10  \n",
    "#         mcat1 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME1, N_WALKERS * burnin_cat1)\n",
    "#         be1, post_lnnorm_sd1 = mcat1.get_post_lnnorm()\n",
    "#         # lnevol1, glnvol1 = mcat1.get_post_lnvol(0.6827)\n",
    "\n",
    "#         burnin_cat2 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME2, 0.0).peek_e_mean_stats().estimate_const_break(0) + 10  \n",
    "#         mcat2 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME2, N_WALKERS * burnin_cat2)\n",
    "#         be2, post_lnnorm_sd2 = mcat2.get_post_lnnorm()\n",
    "#         # lnevol2, glnvol2 = mcat2.get_post_lnvol(0.6827)\n",
    "\n",
    "#         mcat1 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME1, N_WALKERS * burnin_cat1)\n",
    "#         mset1 = mcat1.get_mset()\n",
    "\n",
    "#         muM2 = mcat1.get_bestfit_row().dup_array()[4]\n",
    "#         sd_muM2 = mcat1.peek_pstats().get_sd(4) \n",
    "\n",
    "#         mu0 = mcat2.get_bestfit_row().dup_array()[1]\n",
    "#         sd_mu0 = mcat2.peek_pstats().get_sd(1)\n",
    "\n",
    "#         mu1 = mcat2.get_bestfit_row().dup_array()[2]\n",
    "#         sd_mu1 = mcat2.peek_pstats().get_sd(2)\n",
    "\n",
    "#         mu2 = mcat2.get_bestfit_row().dup_array()[3]\n",
    "#         sd_mu2 = mcat2.peek_pstats().get_sd(3)\n",
    "\n",
    "#         bf = np.exp(be1 - be2)\n",
    "        \n",
    "#         bef = pd.concat([bef, pd.DataFrame([{'Min_Mass':mcut, 'Min_Richness': rcut,  'BEQ': be1, \n",
    "#                                              'BEQ Err': post_lnnorm_sd1, 'BEL': be2, 'BEL Err':post_lnnorm_sd2, \n",
    "#                                              'BF': bf, 'muM2':muM2, 'sd_muM2': sd_muM2, \n",
    "#                                              'mu0':mu0, 'sd_mu0': sd_mu0, 'mu1':mu1, 'sd_mu1': sd_mu1, 'mu2':mu2, 'sd_mu2': sd_mu2}])], ignore_index=True)\n",
    "\n",
    "#         # bef = pd.concat([bef, pd.DataFrame([{'Min_Mass':mcut, 'Min_Richness': rcut,  'BEQ': be1, \n",
    "#         #                                      'BEQ Err': post_lnnorm_sd1, 'BEL': be2, 'BEL Err':post_lnnorm_sd2, \n",
    "#         #                                      'BF': bf, 'muM2':muM2, 'sd_muM2': sd_muM2}])], ignore_index=True)\n",
    "\n",
    "#         cDC2_data = Table([mass_data, rich_data, z_data], names=('mass', 'richness', 'redshift'))\n",
    "        \n",
    "#         #Data cut:\n",
    "#         cDC2_data = cDC2_data[cDC2_data['richness'] > rcut]\n",
    "#         cDC2_data = cDC2_data[cDC2_data['mass'] > mcut]\n",
    "#         lnM = np.log(cDC2_data['mass'])\n",
    "#         z = cDC2_data['redshift']\n",
    "\n",
    "#         mset1.pretty_log()\n",
    "#         ext = mset1.peek_by_name('NcClusterMass')\n",
    "#         mean_ext.append(np.array([ext.get_mean(lnM[i], z[i]) for i in range(len(lnM))]))\n",
    "    \n",
    "#     mean_ext_list.append(mean_ext)\n",
    "#     bef_list.append(bef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f6f84f-72e3-4424-947f-08180f5c0f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_to_latex_sci(x, precision=2):\n",
    "\n",
    "    if x == 0:\n",
    "        return f\"{0:.{precision}f}\"\n",
    "\n",
    "    sci_str = f\"{x:.{precision}e}\"\n",
    "    base, exponent = sci_str.split('e')\n",
    "    exponent = int(exponent)\n",
    "\n",
    "    return f\"${base} \\\\times 10^{{{exponent}}}$\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2559e1b-c939-4b1a-be9d-60b025e20f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "RICH_CUT_list = [5, 10, 15, 20, 30, 40]\n",
    "MASS_CUT_list = [1e13, 2e13, 5e13, 8e13, 1e14]\n",
    "    \n",
    "bef_list = []\n",
    "mean_ext_list = []\n",
    "    \n",
    "for mcut in MASS_CUT_list:\n",
    "    \n",
    "    # bef = pd.DataFrame(data = {'Min_Mass':[], 'Min_Richness': [], 'BEQ': [], 'BEQ Err': [], 'BEL': [], 'BEL Err': [], \n",
    "    #                            'BF': [], 'muM2': [], 'sd_muM2': []})\n",
    "    \n",
    "    bef = pd.DataFrame(data = {'Min_Mass':[], 'Min_Richness': [],  \n",
    "                                                'mu0':[], 'mu0_sup': [], 'mu0_inf': [], \n",
    "                                                'mu1':[], 'mu1_sup': [], 'mu1_inf': [], \n",
    "                                                'mu2':[], 'mu2_sup': [], 'mu2_inf': [],\n",
    "                                                'sigma0':[], 'sigma0_sup': [], 'sigma0_inf': [], \n",
    "                                                'sigma1':[], 'sigma1_sup': [], 'sigma1_inf': [], \n",
    "                                                'sigma2':[], 'sigma2_sup': [], 'sigma2_inf': [],\n",
    "                                                'BEQ': [], 'BEQ Err': [], 'BEL': [], \n",
    "                                                'BEL Err':[], 'ln(BF)': []})\n",
    "         \n",
    "    \n",
    "    for rcut in RICH_CUT_list:\n",
    "            \n",
    "        N_WALKERS = 1200\n",
    "        N_RUN = 300\n",
    "            \n",
    "        RICH_CUT = rcut\n",
    "        MASS_CUT = mcut \n",
    "\n",
    "        MODEL1 = 'asc'\n",
    "        #FILE_NAME1 = \"/global/homes/c/cinlima/ESMCMC/with_correction/\"+MODEL1+\"_rmin_\"+str(RICH_CUT)+\"_mmin_\"+str(int(MASS_CUT))+\".fits\"\n",
    "        FILE_NAME1 = \"/global/homes/l/lettieri/ESMCMC/with_correction/\"+MODEL1+\"_rmin_\"+str(RICH_CUT)+\"_mmin_\"+str(int(MASS_CUT))+\".fits\"\n",
    "           \n",
    "        MODEL2 = 'asc'\n",
    "        #FILE_NAME2 = \"/global/homes/c/cinlima/ESMCMC/without_correction/\"+MODEL2+\"_rmin_\"+str(RICH_CUT)+\"_mmin_\"+str(int(MASS_CUT))+\".fits\"\n",
    "        FILE_NAME2 = \"/global/homes/l/lettieri/ESMCMC/without_correction/\"+MODEL2+\"_rmin_\"+str(RICH_CUT)+\"_mmin_\"+str(int(MASS_CUT))+\".fits\"\n",
    "    \n",
    "    \n",
    "        burnin_cat1 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME1, 0.0).peek_e_mean_stats().estimate_const_break(0) + 10  \n",
    "        mcat1 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME1, N_WALKERS * burnin_cat1)\n",
    "        be1, post_lnnorm_sd1 = mcat1.get_post_lnnorm()\n",
    "        # lnevol1, glnvol1 = mcat1.get_post_lnvol(0.6827)\n",
    "    \n",
    "        burnin_cat2 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME2, 0.0).peek_e_mean_stats().estimate_const_break(0) + 10  \n",
    "        mcat2 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME2, N_WALKERS * burnin_cat2)\n",
    "        be2, post_lnnorm_sd2 = mcat2.get_post_lnnorm()\n",
    "        # lnevol2, glnvol2 = mcat2.get_post_lnvol(0.6827)\n",
    "\n",
    "        mu0 = mcat1.get_bestfit_row().dup_array()[1]\n",
    "        # sd_mu0 = mcat2.peek_pstats().get_sd(1)\n",
    "    \n",
    "        mu1 = mcat1.get_bestfit_row().dup_array()[2]\n",
    "        # sd_mu1 = mcat2.peek_pstats().get_sd(2)\n",
    "    \n",
    "        mu2 = mcat1.get_bestfit_row().dup_array()[3]\n",
    "        # sd_mu2 = mcat2.peek_pstats().get_sd(3)\n",
    "\n",
    "        sigma0 = mcat1.get_bestfit_row().dup_array()[4]\n",
    "        # sd_mu0 = mcat2.peek_pstats().get_sd(1)\n",
    "    \n",
    "        sigma1 = mcat1.get_bestfit_row().dup_array()[5]\n",
    "        # sd_mu1 = mcat2.peek_pstats().get_sd(2)\n",
    "    \n",
    "        sigma2 = mcat1.get_bestfit_row().dup_array()[6]\n",
    "        # sd_mu2 = mcat2.peek_pstats().get_sd(3)\n",
    "    \n",
    "        # bf = np.exp(be1 - be2)\n",
    "       \n",
    "        # if bf < 1e300:\n",
    "        #     bf = float_to_latex_sci(bf) \n",
    "        \n",
    "        # else:\n",
    "        #     bf = '$\\infty$'\n",
    "\n",
    "        lnbf = be1 - be2\n",
    "\n",
    "        # if np.exp(be1 - be2) > 1e200:\n",
    "        #     bf = bf.apply(float_to_latex_sci) \n",
    "        \n",
    "        # else:\n",
    "        #     bf = np.exp(be1 - be2)          \n",
    "        \n",
    "        \n",
    "        data_fit_full = pd.DataFrame(fits.open(FILE_NAME1)[1].data).iloc[:, 1:7].T\n",
    "        data_fit_void = np.array(data_fit_full)\n",
    "        data_fit = []\n",
    "        for item in data_fit_void:\n",
    "            arr= np.array(item)\n",
    "            data_fit.append(np.asarray(arr.tolist()))\n",
    "            \n",
    "        names = [\n",
    "            '1',\n",
    "            '2',\n",
    "            '3',\n",
    "            '4',\n",
    "            '5',\n",
    "            '6',\n",
    "        ]\n",
    "        labels=[r\"\\mu_{0}\", r\"\\mu_{1}\", r\"\\mu_{2}\", r\"\\sigma_{0}\", r\"\\sigma_{1}\", r\"\\sigma_{2}\"]\n",
    "        settings = {\n",
    "            \"mult_bias_correction_order\": 0,\n",
    "            \"smooth_scale_2D\": 3,\n",
    "            \"smooth_scale_1D\": 3,\n",
    "            \"boundary_correction_order\": 0,\n",
    "        }\n",
    "        samples1 = MCSamples(samples=data_fit, names=names, labels=labels, settings=settings)\n",
    "        samples1.removeBurn(0.3)\n",
    "            \n",
    "        mu0_inf = samples1.get1DDensity(0).getLimits(0.95)[0]\n",
    "        mu0_sup = samples1.get1DDensity(0).getLimits(0.95)[1]\n",
    "    \n",
    "        mu1_inf = samples1.get1DDensity(1).getLimits(0.95)[0]\n",
    "        mu1_sup = samples1.get1DDensity(1).getLimits(0.95)[1]\n",
    "    \n",
    "        mu2_inf = samples1.get1DDensity(2).getLimits(0.95)[0]\n",
    "        mu2_sup = samples1.get1DDensity(2).getLimits(0.95)[1]\n",
    "\n",
    "        sigma0_inf = samples1.get1DDensity(3).getLimits(0.95)[0]\n",
    "        sigma0_sup = samples1.get1DDensity(3).getLimits(0.95)[1]\n",
    "    \n",
    "        sigma1_inf = samples1.get1DDensity(4).getLimits(0.95)[0]\n",
    "        sigma1_sup = samples1.get1DDensity(4).getLimits(0.95)[1]\n",
    "    \n",
    "        sigma2_inf = samples1.get1DDensity(5).getLimits(0.95)[0]\n",
    "        sigma2_sup = samples1.get1DDensity(5).getLimits(0.95)[1]\n",
    "\n",
    "            \n",
    "                    \n",
    "        bef = pd.concat([bef, pd.DataFrame([{'Min_Mass':mcut, 'Min_Richness': rcut,   \n",
    "                                                'mu0':mu0, 'mu0_sup': mu0_sup, 'mu0_inf': mu0_inf, \n",
    "                                                'mu1':mu1, 'mu1_sup': mu1_sup, 'mu1_inf': mu1_inf, \n",
    "                                                'mu2':mu2, 'mu2_sup': mu2_sup, 'mu2_inf': mu2_inf,\n",
    "                                                'sigma0':sigma0, 'sigma0_sup': sigma0_sup, 'sigma0_inf': sigma0_inf, \n",
    "                                                'sigma1':sigma1, 'sigma1_sup': sigma1_sup, 'sigma1_inf': sigma1_inf, \n",
    "                                                'sigma2':sigma2, 'sigma2_sup': sigma2_sup, 'sigma2_inf': sigma2_inf,\n",
    "                                                'BEQ': be1, 'BEQ Err': post_lnnorm_sd1, 'BEL': be2, \n",
    "                                                'BEL Err':post_lnnorm_sd2, 'ln(BF)': lnbf}])], ignore_index=True)\n",
    "    \n",
    "        # bef = pd.concat([bef, pd.DataFrame([{'Min_Mass':mcut, 'Min_Richness': rcut,  'BEQ': be1, \n",
    "        #                                      'BEQ Err': post_lnnorm_sd1, 'BEL': be2, 'BEL Err':post_lnnorm_sd2, \n",
    "        #                                      'BF': bf, 'muM2':muM2, 'sd_muM2': sd_muM2}])], ignore_index=True)\n",
    "    \n",
    "        cDC2_data = Table([mass_data, rich_data, z_data], names=('mass', 'richness', 'redshift'))\n",
    "            \n",
    "        #Data cut:\n",
    "        cDC2_data = cDC2_data[cDC2_data['richness'] > rcut]\n",
    "        cDC2_data = cDC2_data[cDC2_data['mass'] > mcut]\n",
    "        lnM = np.log(cDC2_data['mass'])\n",
    "        z = cDC2_data['redshift']\n",
    "    \n",
    "            \n",
    "    bef_list.append(bef)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a43e84-3f8a-419b-98eb-3fa0a70b6bf7",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caeea3c-b643-47a7-b818-1e11e0e97ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_datafame = pd.concat(bef_list)\n",
    "bf_datafame = bf_datafame.reset_index(drop=True)\n",
    "bf_datafame.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f2638-138d-40f2-873c-1a2eaf6dc4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_trend = bf_datafame.drop(['BEQ', 'BEQ Err', 'BEL','BEL Err'], axis=1)\n",
    "\n",
    "paper_trend['mu0_sup'] = paper_trend['mu0_sup'] - paper_trend['mu0']\n",
    "paper_trend['mu1_sup'] = paper_trend['mu1_sup'] - paper_trend['mu1']\n",
    "paper_trend['mu2_sup'] = paper_trend['mu2_sup'] - paper_trend['mu2']\n",
    "\n",
    "paper_trend['mu0_inf'] = paper_trend['mu0_inf'] - paper_trend['mu0']\n",
    "paper_trend['mu1_inf'] = paper_trend['mu1_inf'] - paper_trend['mu1']\n",
    "paper_trend['mu2_inf'] = paper_trend['mu2_inf'] - paper_trend['mu2']\n",
    "\n",
    "paper_trend['mu0'] = paper_trend.apply(lambda row: f\"${row['mu0']:.2f}^{{+{row['mu0_sup']:.2f}}}_{{{row['mu0_inf']:.2f}}}$\", axis=1)\n",
    "paper_trend['mu1'] = paper_trend.apply(lambda row: f\"${row['mu1']:.2f}^{{+{row['mu1_sup']:.2f}}}_{{{row['mu1_inf']:.2f}}}$\", axis=1)\n",
    "paper_trend['mu2'] = paper_trend.apply(lambda row: f\"${row['mu2']:.2f}^{{+{row['mu2_sup']:.2f}}}_{{{row['mu2_inf']:.2f}}}$\", axis=1)\n",
    "\n",
    "paper_trend['sigma0_sup'] = paper_trend['sigma0_sup'] - paper_trend['sigma0']\n",
    "paper_trend['sigma1_sup'] = paper_trend['sigma1_sup'] - paper_trend['sigma1']\n",
    "paper_trend['sigma2_sup'] = paper_trend['sigma2_sup'] - paper_trend['sigma2']\n",
    "\n",
    "paper_trend['sigma0_inf'] = paper_trend['sigma0_inf'] - paper_trend['sigma0']\n",
    "paper_trend['sigma1_inf'] = paper_trend['sigma1_inf'] - paper_trend['sigma1']\n",
    "paper_trend['sigma2_inf'] = paper_trend['sigma2_inf'] - paper_trend['sigma2']\n",
    "\n",
    "paper_trend['sigma0'] = paper_trend.apply(lambda row: f\"${row['sigma0']:.2f}^{{+{row['sigma0_sup']:.2f}}}_{{{row['sigma0_inf']:.2f}}}$\", axis=1)\n",
    "paper_trend['sigma1'] = paper_trend.apply(lambda row: f\"${row['sigma1']:.2f}^{{+{row['sigma1_sup']:.2f}}}_{{{row['sigma1_inf']:.2f}}}$\", axis=1)\n",
    "paper_trend['sigma2'] = paper_trend.apply(lambda row: f\"${row['sigma2']:.2f}^{{+{row['sigma2_sup']:.2f}}}_{{{row['sigma2_inf']:.2f}}}$\", axis=1)\n",
    "\n",
    "# Aplicar ao DataFrame\n",
    "paper_trend['Min_Mass'] = paper_trend['Min_Mass'].apply(float_to_latex_sci)\n",
    "\n",
    "\n",
    "# pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "\n",
    "paper_trend_df = paper_trend.rename(columns={'Min_Mass': '$M_c$', 'Min_Richness': '$\\lambda_c$', \n",
    "                                             'mu0': '$\\mu_0$', 'mu1': '$\\mu_1$','mu2': '$\\mu_2$', \n",
    "                                             'sigma0': '$\\sigma_0$', 'sigma1': '$\\sigma_1$','sigma2': '$\\sigma_2$' })\n",
    "\n",
    "paper_trend_df = paper_trend_df.drop(['mu0_sup', 'mu1_sup', 'mu2_sup', 'mu0_inf', 'mu1_inf', 'mu2_inf', \n",
    "                                      'sigma0_sup', 'sigma1_sup', 'sigma2_sup', 'sigma0_inf', 'sigma1_inf', 'sigma2_inf'], axis=1)\n",
    "\n",
    "paper_trend_df = paper_trend_df.reset_index(drop=True)\n",
    "\n",
    "paper_trend_df\n",
    "\n",
    "\n",
    "# with open('mytable.tex','w') as tf:\n",
    "#     tf.write(paper_trend_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ace7a-d618-4cb6-88db-59edad6f24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,6))\n",
    "\n",
    "# for i in range(0,3): \n",
    "    \n",
    "#     plt.plot(bef_list[i][\"Min_Richness\"], bef_list[i][\"BF\"], label = f'{MASS_CUT_list[i]:.2}', ls = '-.', linewidth = 1.0, marker = 'o')\n",
    "#     plt.yscale(\"log\")\n",
    "    \n",
    "# linewidth = 1.0            \n",
    "# plt.axline((0, 10), (50, 10), c = 'darkcyan', ls= '--', label = 'BF = 10')\n",
    "# plt.axline((0, 1), (50, 1), c = 'k', ls= '--', label = 'BF = 0')\n",
    "# plt.axline((0, 100), (50, 100), c = 'r', ls= '--', label = 'BF = 100')\n",
    "# # plt.axvline(x = 15, color = 'k', ls= '--', linewidth = 0.3 )\n",
    "\n",
    "\n",
    "# lgd = plt.legend(fontsize=12, bbox_to_anchor=(1.0, 1.0)) \n",
    "\n",
    "# plt.ylabel('Bayes factor', fontsize=16)\n",
    "# plt.xlabel(r'$\\lambda_{c}$', fontsize=16)\n",
    "# # plt.title('Bayes factor' )\n",
    "\n",
    "# plt.grid()\n",
    "# plt.xticks(fontsize=12)\n",
    "# plt.yticks(fontsize=12)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae905ca4-202a-4b1b-9e5e-a3300aae9639",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(3,2))\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "# fig.suptitle('Mean parameters for each data selection')\n",
    "\n",
    "for i in range(0,5):\n",
    "    # axs[0].errorbar(bef_list[i][\"Min_Richness\"],  bef_list[i][\"mu0\"], yerr= bef_list[i][\"sd_mu0\"], ls= '--', linewidth = 1.0, ecolor = \"black\", capsize=3, ms = 3.5, marker = 'o',  label = f'{MASS_CUT_list[i]:.2}')\n",
    "    axs[0].plot(bef_list[i][\"Min_Richness\"], bef_list[i][\"mu0\"], label = f'{MASS_CUT_list[i]:.2}',ls = '-.', linewidth = 0.5, marker = 'o', ms = 3)\n",
    "    axs[0].fill_between(bef_list[i][\"Min_Richness\"],  bef_list[i][\"mu0_inf\"], bef_list[i][\"mu0_sup\"],  alpha=0.2)\n",
    "\n",
    "for i in range(0,5):    \n",
    "    axs[1].plot(bef_list[i][\"Min_Richness\"], bef_list[i][\"mu1\"], label = f'{MASS_CUT_list[i]:.2}',ls = '-.', linewidth = 0.5, marker = 'o', ms = 3)\n",
    "    # axs[1].errorbar(bef_list[i][\"Min_Richness\"],  bef_list[i][\"mu1\"], yerr= bef_list[i][\"sd_mu1\"], ls= '--', linewidth = 1.0, ecolor = \"black\", capsize=3, marker = 'o', ms = 3.5,  label = f'{MASS_CUT_list[i]:.2}')\n",
    "    axs[1].fill_between(bef_list[i][\"Min_Richness\"], bef_list[i][\"mu1_inf\"], bef_list[i][\"mu1_sup\"],  alpha=0.2)\n",
    "\n",
    "        \n",
    "for i in range(0,5):\n",
    "    axs[2].plot(bef_list[i][\"Min_Richness\"], bef_list[i][\"mu2\"], label = f'{MASS_CUT_list[i]:.2}',ls = '-.', linewidth = 0.5, marker = 'o', ms = 3)\n",
    "    # axs[2].errorbar(bef_list[i][\"Min_Richness\"],  bef_list[i][\"mu2\"], yerr= bef_list[i][\"sd_mu2\"], ls= '--', linewidth = 1.0, ecolor = \"black\", capsize=3, marker = 'o', ms = 3.5,  label = f'{MASS_CUT_list[i]:.2}')\n",
    "    axs[2].fill_between(bef_list[i][\"Min_Richness\"], bef_list[i][\"mu2_inf\"], bef_list[i][\"mu2_sup\"],  alpha=0.2)\n",
    "\n",
    "axs[0].set_ylabel('$\\mu0$')\n",
    "axs[1].set_ylabel('$\\mu1$')\n",
    "axs[2].set_ylabel('$\\mu2$')\n",
    "\n",
    "axs[2].set_xlabel('$\\lambda_{c}$')\n",
    "\n",
    "# plt.legend(bbox_to_anchor=(0.23, 0.45))\n",
    "lgd = plt.legend(bbox_to_anchor=(1.4, 3.0), title='Mass cut:')\n",
    "\n",
    "fmt = lambda x, pos: '{:.2f}'.format(x, pos)\n",
    "axs[0].yaxis.set_major_formatter(mpl.ticker.FuncFormatter(fmt))\n",
    "axs[1].yaxis.set_major_formatter(mpl.ticker.FuncFormatter(fmt))\n",
    "axs[2].yaxis.set_major_formatter(mpl.ticker.FuncFormatter(fmt))\n",
    "\n",
    "# plt.show()\n",
    "# plt.savefig('mu_lamb_with_correction_mcmc2', dpi=500, bbox_extra_artists=([lgd]), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eb1936-36aa-4b26-a5f7-cede50aeecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "RICH_CUT_list = [5, 10, 15, 20, 30, 40]\n",
    "MASS_CUT_list = [1e13, 2e13, 5e13, 8e13, 1e14]\n",
    "    \n",
    "def bef_list(model_type, RICH_CUT_list, MASS_CUT_list):\n",
    "\n",
    "    bef_list = []\n",
    "    \n",
    "    for mcut in MASS_CUT_list:\n",
    "          \n",
    "        bef = pd.DataFrame(data = {'Min_Mass':[], 'Min_Richness': [],\n",
    "                                   'mu0':[], 'mu0_sup': [], 'mu0_inf': [], \n",
    "                                   'mu1':[], 'mu1_sup': [], 'mu1_inf': [], \n",
    "                                   'mu2':[], 'mu2_sup': [], 'mu2_inf': []}) \n",
    "        \n",
    "        for rcut in RICH_CUT_list:\n",
    "                \n",
    "            N_WALKERS = 1200\n",
    "            N_RUN = 300\n",
    "                \n",
    "            RICH_CUT = rcut\n",
    "            MASS_CUT = mcut \n",
    "                \n",
    "            MODEL2 = 'asc'\n",
    "            FILE_NAME2 = \"/global/homes/c/cinlima/ESMCMC/\"+model_type+\"/\"+MODEL2+\"_rmin_\"+str(RICH_CUT)+\"_mmin_\"+str(int(MASS_CUT))+\".fits\"\n",
    "                \n",
    "            burnin_cat2 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME2, 0.0).peek_e_mean_stats().estimate_const_break(0) + 10  \n",
    "            mcat2 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME2, N_WALKERS * burnin_cat2)\n",
    "            be2, post_lnnorm_sd2 = mcat2.get_post_lnnorm()\n",
    "            # lnevol2, glnvol2 = mcat2.get_post_lnvol(0.6827)\n",
    "        \n",
    "            mu0 = mcat2.get_bestfit_row().dup_array()[1]\n",
    "            # sd_mu0 = mcat2.peek_pstats().get_sd(1)\n",
    "        \n",
    "            mu1 = mcat2.get_bestfit_row().dup_array()[2]\n",
    "            # sd_mu1 = mcat2.peek_pstats().get_sd(2)\n",
    "        \n",
    "            mu2 = mcat2.get_bestfit_row().dup_array()[3]\n",
    "            # sd_mu2 = mcat2.peek_pstats().get_sd(3)\n",
    "                    \n",
    "                \n",
    "            data_fit_full = pd.DataFrame(fits.open(FILE_NAME2)[1].data).iloc[:, 1:7].T\n",
    "            data_fit_void = np.array(data_fit_full)\n",
    "            data_fit = []\n",
    "            for item in data_fit_void:\n",
    "                arr= np.array(item)\n",
    "                data_fit.append(np.asarray(arr.tolist()))\n",
    "                \n",
    "            names = [\n",
    "                '1',\n",
    "                '2',\n",
    "                '3',\n",
    "                '4',\n",
    "                '5',\n",
    "                '6',\n",
    "            ]\n",
    "            labels=[r\"\\mu_{0}\", r\"\\mu_{1}\", r\"\\mu_{2}\", r\"\\sigma_{0}\", r\"\\sigma_{1}\", r\"\\sigma_{2}\"]\n",
    "            settings = {\n",
    "                \"mult_bias_correction_order\": 0,\n",
    "                \"smooth_scale_2D\": 3,\n",
    "                \"smooth_scale_1D\": 3,\n",
    "                \"boundary_correction_order\": 0,\n",
    "            }\n",
    "            samples1 = MCSamples(samples=data_fit, names=names, labels=labels, settings=settings)\n",
    "            samples1.removeBurn(0.3)\n",
    "                \n",
    "            mu0_sup = samples1.get1DDensity(0).getLimits(0.95)[0]\n",
    "            mu0_inf = samples1.get1DDensity(0).getLimits(0.95)[1]\n",
    "        \n",
    "            mu1_sup = samples1.get1DDensity(1).getLimits(0.95)[0]\n",
    "            mu1_inf = samples1.get1DDensity(1).getLimits(0.95)[1]\n",
    "        \n",
    "            mu2_sup = samples1.get1DDensity(2).getLimits(0.95)[0]\n",
    "            mu2_inf = samples1.get1DDensity(2).getLimits(0.95)[1]\n",
    "                \n",
    "                        \n",
    "            bef = pd.concat([bef, pd.DataFrame([{'Min_Mass':mcut, 'Min_Richness': rcut,  \n",
    "                                                    'mu0':mu0, 'mu0_sup': mu0_sup, 'mu0_inf': mu0_inf, \n",
    "                                                    'mu1':mu1, 'mu1_sup': mu1_sup, 'mu1_inf': mu1_inf, \n",
    "                                                    'mu2':mu2, 'mu2_sup': mu2_sup, 'mu2_inf': mu2_inf}])], ignore_index=True)\n",
    "        \n",
    "            cDC2_data = Table([mass_data, rich_data, z_data], names=('mass', 'richness', 'redshift'))\n",
    "                \n",
    "            #Data cut:\n",
    "            cDC2_data = cDC2_data[cDC2_data['richness'] > rcut]\n",
    "            cDC2_data = cDC2_data[cDC2_data['mass'] > mcut]\n",
    "            lnM = np.log(cDC2_data['mass'])\n",
    "            z = cDC2_data['redshift']\n",
    "        \n",
    "                \n",
    "        bef_list.append(bef)\n",
    "\n",
    "    return bef_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f196148-6cc3-4a92-bef9-991e78a92c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "bef_list1 = bef_list(\"without_correction\", RICH_CUT_list, MASS_CUT_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ef4d01-f5a2-40b2-9476-6a7b2cd02e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "bef_list2 = bef_list(\"with_correction\", RICH_CUT_list, MASS_CUT_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b3cac-e0b8-4465-a18a-408c2c30d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_rc_params_article(ncol=2)\n",
    "set_rc_params_article(nrows=1)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, sharex=True, sharey='row')\n",
    "fig.subplots_adjust(wspace=0.30, hspace=0)  # Espaço horizontal apenas\n",
    "\n",
    "def get_global_ylim(bef_list1, bef_list2, key_inf, key_sup):\n",
    "    all_vals = []\n",
    "    for bef in bef_list1 + bef_list2:\n",
    "        all_vals.extend(bef[key_inf])\n",
    "        all_vals.extend(bef[key_sup])\n",
    "    return np.min(all_vals), np.max(all_vals)\n",
    "\n",
    "# Calcular os y-limits para cada linha\n",
    "ylim_mu0 = get_global_ylim(bef_list1, bef_list2, \"mu0_inf\", \"mu0_sup\")\n",
    "ylim_mu1 = get_global_ylim(bef_list1, bef_list2, \"mu1_inf\", \"mu1_sup\")\n",
    "ylim_mu2 = get_global_ylim(bef_list1, bef_list2, \"mu2_inf\", \"mu2_sup\")\n",
    "\n",
    "# Plot - Primeira Coluna (bef_list1)\n",
    "for i in range(5):\n",
    "    axs[0, 0].plot(bef_list1[i][\"Min_Richness\"], bef_list1[i][\"mu0\"], label=f'{MASS_CUT_list[i]:.2}', ls='-.', lw=0.5, marker='o', ms=3)\n",
    "    axs[0, 0].fill_between(bef_list1[i][\"Min_Richness\"], bef_list1[i][\"mu0_inf\"], bef_list1[i][\"mu0_sup\"], alpha=0.2)\n",
    "\n",
    "    axs[1, 0].plot(bef_list1[i][\"Min_Richness\"], bef_list1[i][\"mu1\"], ls='-.', lw=0.5, marker='o', ms=3)\n",
    "    axs[1, 0].fill_between(bef_list1[i][\"Min_Richness\"], bef_list1[i][\"mu1_inf\"], bef_list1[i][\"mu1_sup\"], alpha=0.2)\n",
    "\n",
    "    axs[2, 0].plot(bef_list1[i][\"Min_Richness\"], bef_list1[i][\"mu2\"], ls='-.', lw=0.5, marker='o', ms=3)\n",
    "    axs[2, 0].fill_between(bef_list1[i][\"Min_Richness\"], bef_list1[i][\"mu2_inf\"], bef_list1[i][\"mu2_sup\"], alpha=0.2)\n",
    "\n",
    "# axs[0, 0].plot(bef_list_r1[\"Min_Redshift\"], bef_list_r1[\"mu0\"], ls = '-.', linewidth = 0.5, marker = 'o', ms = 3)\n",
    "# axs[0, 0].fill_between(bef_list_r1[\"Min_Redshift\"],  bef_list_r1[\"mu0_inf\"], bef_list_r1[\"mu0_sup\"],  alpha=0.2)\n",
    "\n",
    "# axs[1, 0].plot(bef_list_r1[\"Min_Redshift\"], bef_list_r1[\"mu1\"],ls = '-.', linewidth = 0.5, marker = 'o', ms = 3)\n",
    "# # axs[1].errorbar(bef_list_r1[\"Min_Redshift\"],  bef_list_r1[\"mu1\"], yerr= bef_list_r1[\"sd_mu1\"], ls= '--', linewidth = 1.0, ecolor = \"black\", capsize=3, marker = 'o', ms = 3.5,  label = f'{MASS_CUT_list:.2}')\n",
    "# axs[1, 0].fill_between(bef_list_r1[\"Min_Redshift\"], bef_list_r1[\"mu1_inf\"], bef_list_r1[\"mu1_sup\"],  alpha=0.2)\n",
    "\n",
    "# axs[2, 0].plot(bef_list_r1[\"Min_Redshift\"], bef_list_r1[\"mu2\"], ls = '-.', linewidth = 0.5, marker = 'o', ms = 3)\n",
    "# # axs[2].errorbar(bef_list_r1[\"Min_Redshift\"],  bef_list_r1[\"mu2\"], yerr= bef_list_r1[\"sd_mu2\"], ls= '--', linewidth = 1.0, ecolor = \"black\", capsize=3, marker = 'o', ms = 3.5,  label = f'{MASS_CUT_list:.2}')\n",
    "# axs[2, 0].fill_between(bef_list_r1[\"Min_Redshift\"], bef_list_r1[\"mu2_inf\"], bef_list_r1[\"mu2_sup\"],  alpha=0.2)\n",
    "\n",
    "\n",
    "\n",
    "# Plot - Segunda Coluna (bef_list2)\n",
    "for i in range(5):\n",
    "    axs[0, 1].plot(bef_list2[i][\"Min_Richness\"], bef_list2[i][\"mu0\"], label=f'{MASS_CUT_list[i]:.2}', ls='-.', lw=0.5, marker='o', ms=3)\n",
    "    axs[0, 1].fill_between(bef_list2[i][\"Min_Richness\"], bef_list2[i][\"mu0_inf\"], bef_list2[i][\"mu0_sup\"], alpha=0.2)\n",
    "\n",
    "    axs[1, 1].plot(bef_list2[i][\"Min_Richness\"], bef_list2[i][\"mu1\"], ls='-.', lw=0.5, marker='o', ms=3)\n",
    "    axs[1, 1].fill_between(bef_list2[i][\"Min_Richness\"], bef_list2[i][\"mu1_inf\"], bef_list2[i][\"mu1_sup\"], alpha=0.2)\n",
    "\n",
    "    axs[2, 1].plot(bef_list2[i][\"Min_Richness\"], bef_list2[i][\"mu2\"], ls='-.', lw=0.5, marker='o', ms=3)\n",
    "    axs[2, 1].fill_between(bef_list2[i][\"Min_Richness\"], bef_list2[i][\"mu2_inf\"], bef_list2[i][\"mu2_sup\"], alpha=0.2)\n",
    "\n",
    "# axs[0, 1].plot(bef_list_r2[\"Min_Redshift\"], bef_list_r2[\"mu0\"], ls = '-.', linewidth = 0.5, marker = 'o', ms = 3)\n",
    "# axs[0, 1].fill_between(bef_list_r2[\"Min_Redshift\"],  bef_list_r2[\"mu0_inf\"], bef_list_r2[\"mu0_sup\"],  alpha=0.2)\n",
    "\n",
    "# axs[1, 1].plot(bef_list_r2[\"Min_Redshift\"], bef_list_r2[\"mu1\"],ls = '-.', linewidth = 0.5, marker = 'o', ms = 3)\n",
    "# # axs[1].errorbar(bef_list_r2[\"Min_Redshift\"],  bef_list_r2[\"mu1\"], yerr= bef_list_r2[\"sd_mu1\"], ls= '--', linewidth = 1.0, ecolor = \"black\", capsize=3, marker = 'o', ms = 3.5,  label = f'{MASS_CUT_list:.2}')\n",
    "# axs[1, 1].fill_between(bef_list_r2[\"Min_Redshift\"], bef_list_r2[\"mu1_inf\"], bef_list_r2[\"mu1_sup\"],  alpha=0.2)\n",
    "\n",
    "# axs[2, 1].plot(bef_list_r2[\"Min_Redshift\"], bef_list_r2[\"mu2\"], ls = '-.', linewidth = 0.5, marker = 'o', ms = 3)\n",
    "# # axs[2].errorbar(bef_list_r2[\"Min_Redshift\"],  bef_list_r2[\"mu2\"], yerr= bef_list_r2[\"sd_mu2\"], ls= '--', linewidth = 1.0, ecolor = \"black\", capsize=3, marker = 'o', ms = 3.5,  label = f'{MASS_CUT_list:.2}')\n",
    "# axs[2, 1].fill_between(bef_list_r2[\"Min_Redshift\"], bef_list_r2[\"mu2_inf\"], bef_list_r2[\"mu2_sup\"],  alpha=0.2)\n",
    "\n",
    "\n",
    "# Aplicar os mesmos y-limits por linha\n",
    "axs[0, 0].set_ylim(ylim_mu0)\n",
    "axs[0, 1].set_ylim(ylim_mu0)\n",
    "axs[1, 0].set_ylim(ylim_mu1)\n",
    "axs[1, 1].set_ylim(ylim_mu1)\n",
    "axs[2, 0].set_ylim(ylim_mu2)\n",
    "axs[2, 1].set_ylim(ylim_mu2)\n",
    "\n",
    "# Rótulos dos eixos\n",
    "for row in range(3):\n",
    "    axs[row, 0].set_ylabel(f'$\\mu{row}$')\n",
    "    for col in range(2):\n",
    "        axs[row, col].yaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda x, pos: f'{x:.2f}'))\n",
    "        axs[row, col].tick_params(axis='y', labelleft=True)  # força números do eixo y\n",
    "        axs[row, col].tick_params(axis='x')\n",
    "\n",
    "# Rótulo do eixo x na base\n",
    "axs[2, 0].set_xlabel('$\\lambda_{c}$')\n",
    "axs[2, 1].set_xlabel('$\\lambda_{c}$')\n",
    "\n",
    "# axs[2, 0].set_xlabel('$z_{max}$ > z')\n",
    "# axs[2, 1].set_xlabel('$z_{max}$ > z')\n",
    "\n",
    "axs[0, 0].set_title(\"Without Correction\")\n",
    "axs[0, 1].set_title(\"With Correction\")\n",
    "\n",
    "# axs[0, 0].set_title(\"Simple ID\")\n",
    "# axs[0, 1].set_title(\"Clevar ID\")\n",
    "\n",
    "\n",
    "handles, labels = axs[0, 0].get_legend_handles_labels()\n",
    "lgd = fig.legend(handles, labels,  bbox_to_anchor=(0.45, 0.75), framealpha=1.0, title='Mass cut:')\n",
    "loc = \"center\"\n",
    "plt.savefig('mu_lamb_comparison.pdf', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.savefig('mu_lamb_comparison.png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c64588-804f-4841-b78f-eaa2cdb04104",
   "metadata": {},
   "outputs": [],
   "source": [
    "RED_CUT_list = [0.3, 0.5, 0.8, 1.2]\n",
    "    \n",
    "def bef_list_redshift(model_type, RED_CUT_list):\n",
    "\n",
    "    bef_list = []\n",
    "    \n",
    "    for RED_CUT in RED_CUT_list:\n",
    "        cDC2_data = Table([mass_data, rich_data, z_data], names=('mass', 'richness', 'redshift'))\n",
    "            \n",
    "        #Data cut:\n",
    "        cDC2_data = cDC2_data[cDC2_data['redshift'] < RED_CUT]         \n",
    "    \n",
    "        N_WALKERS = 1200\n",
    "        N_RUN = 300\n",
    "                \n",
    "        MODEL2 = 'asc'\n",
    "        FILE_NAME2 = \"/global/homes/c/cinlima/ESMCMC/\"+model_type+\"/\"+MODEL2+\"_zmax_\"+str(RED_CUT)+\".fits\"\n",
    "        \n",
    "              \n",
    "        bef = pd.DataFrame(data = {'Min_Redshift':[],\n",
    "                                   'mu0':[], 'mu0_sup': [], 'mu0_inf': [], \n",
    "                                   'mu1':[], 'mu1_sup': [], 'mu1_inf': [], \n",
    "                                   'mu2':[], 'mu2_sup': [], 'mu2_inf': []}) \n",
    "        \n",
    " \n",
    "        burnin_cat2 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME2, 0.0).peek_e_mean_stats().estimate_const_break(0) + 10  \n",
    "        mcat2 = Ncm.MSetCatalog.new_from_file_ro(FILE_NAME2, N_WALKERS * burnin_cat2)\n",
    "        be2, post_lnnorm_sd2 = mcat2.get_post_lnnorm()\n",
    "        # lnevol2, glnvol2 = mcat2.get_post_lnvol(0.6827)\n",
    "        \n",
    "        mu0 = mcat2.get_bestfit_row().dup_array()[1]\n",
    "        # sd_mu0 = mcat2.peek_pstats().get_sd(1)\n",
    "        \n",
    "        mu1 = mcat2.get_bestfit_row().dup_array()[2]\n",
    "        # sd_mu1 = mcat2.peek_pstats().get_sd(2)\n",
    "        \n",
    "        mu2 = mcat2.get_bestfit_row().dup_array()[3]\n",
    "        # sd_mu2 = mcat2.peek_pstats().get_sd(3)\n",
    "                    \n",
    "                \n",
    "        data_fit_full = pd.DataFrame(fits.open(FILE_NAME2)[1].data).iloc[:, 1:7].T\n",
    "        data_fit_void = np.array(data_fit_full)\n",
    "        data_fit = []\n",
    "        for item in data_fit_void:\n",
    "            arr= np.array(item)\n",
    "            data_fit.append(np.asarray(arr.tolist()))\n",
    "                \n",
    "        names = [\n",
    "            '1',\n",
    "            '2',\n",
    "            '3',\n",
    "            '4',\n",
    "            '5',\n",
    "            '6',\n",
    "        ]\n",
    "        labels=[r\"\\mu_{0}\", r\"\\mu_{1}\", r\"\\mu_{2}\", r\"\\sigma_{0}\", r\"\\sigma_{1}\", r\"\\sigma_{2}\"]\n",
    "        settings = {\n",
    "            \"mult_bias_correction_order\": 0,\n",
    "            \"smooth_scale_2D\": 3,\n",
    "            \"smooth_scale_1D\": 3,\n",
    "            \"boundary_correction_order\": 0,\n",
    "        }\n",
    "        samples1 = MCSamples(samples=data_fit, names=names, labels=labels, settings=settings)\n",
    "        samples1.removeBurn(0.3)\n",
    "                \n",
    "        mu0_sup = samples1.get1DDensity(0).getLimits(0.95)[0]\n",
    "        mu0_inf = samples1.get1DDensity(0).getLimits(0.95)[1]\n",
    "        \n",
    "        mu1_sup = samples1.get1DDensity(1).getLimits(0.95)[0]\n",
    "        mu1_inf = samples1.get1DDensity(1).getLimits(0.95)[1]\n",
    "        \n",
    "        mu2_sup = samples1.get1DDensity(2).getLimits(0.95)[0]\n",
    "        mu2_inf = samples1.get1DDensity(2).getLimits(0.95)[1]\n",
    "                \n",
    "                        \n",
    "        bef = pd.concat([bef, pd.DataFrame([{'Min_Redshift':RED_CUT,  \n",
    "                                                'mu0':mu0, 'mu0_sup': mu0_sup, 'mu0_inf': mu0_inf, \n",
    "                                                'mu1':mu1, 'mu1_sup': mu1_sup, 'mu1_inf': mu1_inf, \n",
    "                                                'mu2':mu2, 'mu2_sup': mu2_sup, 'mu2_inf': mu2_inf}])], ignore_index=True)\n",
    "                        \n",
    "        bef_list.append(bef)\n",
    "\n",
    "    return pd.concat(bef_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229a0c16-0612-4385-9e53-bdf61521e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bef_list_r1 = bef_list_redshift(\"redshift_analysis_nocorr\", RED_CUT_list)\n",
    "bef_list_r2 = bef_list_redshift(\"redshift_analysis\", RED_CUT_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f97936f-d3af-4fd3-aab7-a8b97d6d44c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(6,4))\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "# fig.suptitle('Mean parameters for each data selection')\n",
    "\n",
    "# axs[0].errorbar(bef_list[i][\"Min_Richness\"],  bef_list[i][\"mu0\"], yerr= bef_list[i][\"sd_mu0\"], ls= '--', linewidth = 1.0, ecolor = \"black\", capsize=3, ms = 3.5, marker = 'o',  label = f'{MASS_CUT_list[i]:.2}')\n",
    "axs[0].plot(bef_list_r[\"Min_Redshift\"], bef_list_r[\"mu0\"], ls = '-.', linewidth = 0.5, marker = 'o', ms = 3)\n",
    "axs[0].fill_between(bef_list_r[\"Min_Redshift\"],  bef_list_r[\"mu0_inf\"], bef_list_r[\"mu0_sup\"],  alpha=0.2)\n",
    "\n",
    "axs[1].plot(bef_list_r[\"Min_Redshift\"], bef_list_r[\"mu1\"],ls = '-.', linewidth = 0.5, marker = 'o', ms = 3)\n",
    "# axs[1].errorbar(bef_list_r[\"Min_Redshift\"],  bef_list_r[\"mu1\"], yerr= bef_list_r[\"sd_mu1\"], ls= '--', linewidth = 1.0, ecolor = \"black\", capsize=3, marker = 'o', ms = 3.5,  label = f'{MASS_CUT_list:.2}')\n",
    "axs[1].fill_between(bef_list_r[\"Min_Redshift\"], bef_list_r[\"mu1_inf\"], bef_list_r[\"mu1_sup\"],  alpha=0.2)\n",
    "\n",
    "axs[2].plot(bef_list_r[\"Min_Redshift\"], bef_list_r[\"mu2\"], ls = '-.', linewidth = 0.5, marker = 'o', ms = 3)\n",
    "# axs[2].errorbar(bef_list_r[\"Min_Redshift\"],  bef_list_r[\"mu2\"], yerr= bef_list_r[\"sd_mu2\"], ls= '--', linewidth = 1.0, ecolor = \"black\", capsize=3, marker = 'o', ms = 3.5,  label = f'{MASS_CUT_list:.2}')\n",
    "axs[2].fill_between(bef_list_r[\"Min_Redshift\"], bef_list_r[\"mu2_inf\"], bef_list_r[\"mu2_sup\"],  alpha=0.2)\n",
    "\n",
    "axs[0].set_ylabel('$\\mu0$')\n",
    "axs[1].set_ylabel('$\\mu1$')\n",
    "axs[2].set_ylabel('$\\mu2$')\n",
    "\n",
    "axs[2].set_xlabel('$\\lambda_{c}$')\n",
    "\n",
    "# plt.legend(bbox_to_anchor=(0.23, 0.45))\n",
    "# lgd = plt.legend(bbox_to_anchor=(1.4, 3.0), title='Mass cut:')\n",
    "\n",
    "fmt = lambda x, pos: '{:.2f}'.format(x, pos)\n",
    "axs[0].yaxis.set_major_formatter(mpl.ticker.FuncFormatter(fmt))\n",
    "axs[1].yaxis.set_major_formatter(mpl.ticker.FuncFormatter(fmt))\n",
    "axs[2].yaxis.set_major_formatter(mpl.ticker.FuncFormatter(fmt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267317a-666f-49fa-99aa-2cf6d8f603b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for i in range(0,5):\n",
    "    # plt.plot(bef_list[i][\"Min_Richness\"], bef_list[i][\"muM2\"], label = f'{MASS_CUT_list[i]:.2}',ls = '-.', linewidth = 0.5, marker = 'o')\n",
    "    # plt.yscale(\"log\")\n",
    "    # plt.errorbar(bef_list[i][\"Min_Richness\"],  bef_list[i][\"mu0\"], yerr= bef_list[i][\"sd_mu0\"], ls= '--', linewidth = 1.0, ecolor = \"black\", capsize=3, marker = 'o',  label = f'{MASS_CUT_list[i]:.2}')\n",
    "    plt.ylabel('$\\mu0$', fontsize=14)\n",
    "    plt.xlabel(r'$\\lambda_{c}$', fontsize=14)\n",
    "    plt.title('$\\mu0$ vs $\\lambda_{c}$ for each min mass' )\n",
    "    plt.fill_between(bef_list[i][\"Min_Richness\"], bef_list[i][\"mu0\"] - bef_list[i][\"sd_mu0\"], bef_list[i][\"mu0\"] + bef_list[i][\"sd_mu0\"],  alpha=0.2)\n",
    "\n",
    "# plt.axline((0, 0), (50, 0), c = 'k', ls= '--', label = 'mu_M2 = 0.0')        \n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ad86b6-0c54-4293-a0ae-ebf9ff80efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for i in range(0,5):\n",
    "    # plt.plot(bef_list[i][\"Min_Richness\"], bef_list[i][\"muM2\"], label = f'{MASS_CUT_list[i]:.2}',ls = '-.', linewidth = 0.5, marker = 'o')\n",
    "    # plt.yscale(\"log\")\n",
    "    plt.errorbar(bef_list[i][\"Min_Richness\"],  bef_list[i][\"mu1\"], yerr= bef_list[i][\"sd_mu1\"], ls= '--', linewidth = 1.0, ecolor = \"black\", capsize=3, marker = 'o',  label = f'{MASS_CUT_list[i]:.2}')\n",
    "    plt.ylabel('$\\mu1$', fontsize=14)\n",
    "    plt.xlabel(r'Richness $\\lambda$', fontsize=14)\n",
    "    plt.title('$\\mu1$ vs min richness for each min mass' )\n",
    "    plt.fill_between(bef_list[i][\"Min_Richness\"], bef_list[i][\"mu1\"] - bef_list[i][\"sd_mu1\"], bef_list[i][\"mu1\"] + bef_list[i][\"sd_mu1\"],  alpha=0.2)\n",
    "# plt.axline((0, 0), (50, 0), c = 'k', ls= '--', label = 'mu_M2 = 0.0')        \n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15439935-7b05-4699-8ac8-9632e6b52852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,6))\n",
    "\n",
    "# for i in range(0,5):\n",
    "#     # plt.plot(bef_list[i][\"Min_Richness\"], bef_list[i][\"muM2\"], label = f'{MASS_CUT_list[i]:.2}',ls = '-.', linewidth = 0.5, marker = 'o')\n",
    "#     # plt.yscale(\"log\")\n",
    "#     plt.errorbar(bef_list[i][\"Min_Richness\"],  bef_list[i][\"mu2\"], yerr= bef_list[i][\"sd_mu2\"], ls= '--', linewidth = 1.0, ecolor = \"black\", capsize=3, marker = 'o',  label = f'{MASS_CUT_list[i]:.2}')\n",
    "#     plt.ylabel('mu2', fontsize=14)\n",
    "#     plt.xlabel(r'Richness $\\lambda$', fontsize=14)\n",
    "#     plt.title('mu2 vs min richness for each min mass' )\n",
    "\n",
    "# # plt.axline((0, 0), (50, 0), c = 'k', ls= '--', label = 'mu_M2 = 0.0')        \n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e601e534-bde3-4c42-80ca-545e4367f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,6))\n",
    "\n",
    "# for i in range(0,5):\n",
    "#     plt.plot(bef_list[i][\"Min_Richness\"], bef_list[i][\"BF\"], label = f'{MASS_CUT_list[i]:.2}', ls = '-.', linewidth = 1.0, marker = 'o')\n",
    "#     plt.yscale(\"log\")\n",
    "        \n",
    "# plt.axline((0, 10), (50, 10), c = 'darkcyan', ls= '--', label = 'BF = 10')\n",
    "# plt.axline((0, 1), (50, 1), c = 'k', ls= '--', label = 'BF = 0')\n",
    "# plt.axline((0, 100), (50, 100), c = 'r', ls= '--', label = 'BF = 100')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.ylabel('Bayes factor', fontsize=14)\n",
    "# plt.xlabel(r'Richness $\\lambda$', fontsize=14)\n",
    "# plt.title('Bayes factor vs min richness for each min mass' )\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8806f651-96d5-4934-a6f6-a2cfe29c334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,6))\n",
    "\n",
    "# for i in range(0,5):\n",
    "#     # plt.plot(bef_list[i][\"Min_Richness\"], bef_list[i][\"muM2\"], label = f'{MASS_CUT_list[i]:.2}',ls = '-.', linewidth = 0.5, marker = 'o')\n",
    "#     # plt.yscale(\"log\")\n",
    "#     plt.errorbar(bef_list[i][\"Min_Richness\"],  bef_list[i][\"muM2\"], yerr= bef_list[i][\"sd_muM2\"], ls= '--', linewidth = 1.0, ecolor = \"black\", capsize=3, marker = 'o',  label = f'{MASS_CUT_list[i]:.2}')\n",
    "#     plt.ylabel('mu_M2', fontsize=14)\n",
    "#     plt.xlabel(r'Richness $\\lambda$', fontsize=14)\n",
    "#     plt.title('mu_M2 vs min richness for each min mass' )\n",
    "\n",
    "# plt.axline((0, 0), (50, 0), c = 'k', ls= '--', label = 'mu_M2 = 0.0')        \n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d1179d-9b45-484c-aa5b-1c6eeb9ef17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(5,7, figsize=(15, 10), constrained_layout=True)\n",
    " \n",
    "# for i, m in enumerate(MASS_CUT_list):\n",
    "#     for j, r in enumerate(RICH_CUT_list):\n",
    "\n",
    "#         cDC2_data = Table([mass_data, rich_data, z_data], names=('mass', 'richness', 'redshift'))\n",
    "        \n",
    "#         #Data cut:\n",
    "#         cDC2_data = cDC2_data[cDC2_data['richness'] > r]\n",
    "#         cDC2_data = cDC2_data[cDC2_data['mass'] > m]\n",
    "        \n",
    "#         lnM = np.log(cDC2_data['mass'])\n",
    "#         z = cDC2_data['redshift']\n",
    "  \n",
    "#         axs[i, j].scatter(lnM, mean_ext_list[i][j])\n",
    "#         axs[i, j].set_title(f'mass > {m:.1e} \\n richness > {r}')\n",
    "\n",
    "RICH_CUT_list = [5, 10, 15, 20, 30, 40, 50]\n",
    "MASS_CUT_list = [1e13, 2e13, 5e13, 8e13, 1e14]\n",
    "\n",
    "for i, m in enumerate(MASS_CUT_list):\n",
    "    for j, r in enumerate(RICH_CUT_list):\n",
    "\n",
    "        cDC2_data = Table([mass_data, rich_data, z_data], names=('mass', 'richness', 'redshift'))\n",
    "        \n",
    "        #Data cut:\n",
    "        cDC2_data = cDC2_data[cDC2_data['richness'] > r]\n",
    "        cDC2_data = cDC2_data[cDC2_data['mass'] > m]\n",
    "        \n",
    "        lnM = np.log(cDC2_data['mass'])\n",
    "        z = cDC2_data['redshift']\n",
    "  \n",
    "        plt.scatter(lnM, mean_ext_list[i][j])\n",
    "        plt.title(f'mass > {m:.1e}')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5a3537-8f46-40f7-937d-82ed8f355a2c",
   "metadata": {},
   "source": [
    "## Corner plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ecb0dd-c83e-485a-ba1a-506c60aba273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_fit_full = pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/full_data_set_mcmc/asc.fits\")[1].data).iloc[:, 1:7].T\n",
    "data_fit_full = pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/with_correction/asc_rmin_5_mmin_10000000000000.fits\")[1].data).iloc[:, 1:7].T\n",
    "data_fit_void = np.array(data_fit_full)\n",
    "data_fit = []\n",
    "for item in data_fit_void:\n",
    "    arr= np.array(item)\n",
    "    data_fit.append(np.asarray(arr.tolist()))\n",
    "\n",
    "names = [\n",
    "    '1',\n",
    "    '2',\n",
    "    '3',\n",
    "    '4',\n",
    "    '5',\n",
    "    '6',\n",
    "]\n",
    "labels=[r\"\\mu_{0}\", r\"\\mu_{1}\", r\"\\mu_{2}\", r\"\\sigma_{0}\", r\"\\sigma_{1}\", r\"\\sigma_{2}\"]\n",
    "settings = {\n",
    "    \"mult_bias_correction_order\": 0,\n",
    "    \"smooth_scale_2D\": 3,\n",
    "    \"smooth_scale_1D\": 3,\n",
    "    \"boundary_correction_order\": 0,\n",
    "}\n",
    "samples1 = MCSamples(samples=data_fit, names=names, labels=labels, settings=settings)\n",
    "samples1.removeBurn(0.3)\n",
    "\n",
    "print(samples1.get1DDensity(0).getLimits(0.68)[0], samples1.get1DDensity(1).getLimits(0.68)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080aa3a5-8bd2-4c16-8893-73a641d20ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fit_full = pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/with_correction/asc_rmin_5_mmin_10000000000000.fits\")[1].data).iloc[:, 0:7].T\n",
    "data_fit_void = np.array(data_fit_full)\n",
    "data_fit = []\n",
    "for item in data_fit_void:\n",
    "    arr= np.array(item)\n",
    "    data_fit.append(np.asarray(arr.tolist()))\n",
    "\n",
    "names = ['0',\n",
    "    '1',\n",
    "    '2',\n",
    "    '3',\n",
    "    '4',\n",
    "    '5',\n",
    "    '6',\n",
    "]\n",
    "labels=[r\"-2lnL\", r\"\\mu_{0}\", r\"\\mu_{1}\", r\"\\mu_{2}\", r\"\\sigma_{0}\", r\"\\sigma_{1}\", r\"\\sigma_{2}\"]\n",
    "settings = {\n",
    "    \"mult_bias_correction_order\": 0,\n",
    "    \"smooth_scale_2D\": 3,\n",
    "    \"smooth_scale_1D\": 3,\n",
    "    \"boundary_correction_order\": 0,\n",
    "}\n",
    "samples1 = MCSamples(samples=data_fit, names=names, labels=labels, settings=settings)\n",
    "samples1.removeBurn(0.3)\n",
    "\n",
    "print(samples1.get1DDensity(1).getLimits(0.68)[0], samples1.get1DDensity(1).getLimits(0.68)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017daad3-2dba-4cd3-846c-ea877de4aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triangle plot\n",
    "g1 = plots.get_subplot_plotter()\n",
    "\n",
    "g1.settings.legend_fontsize = 18\n",
    "g1.settings.lab_fontsize = 25\n",
    "g1.settings.axes_fontsize = 20\n",
    "\n",
    "\n",
    "g1.triangle_plot(\n",
    "    [samples1],\n",
    "    filled=True,\n",
    "    contour_ls=\"-\",\n",
    "    contour_lws=1,\n",
    "    fontsize=14,\n",
    "    fine_bins=1,\n",
    "    colors=['red'],\n",
    "    line_args=[{'lw':1.2,'ls':'-', 'color':'red'}]\n",
    ")\n",
    "plt.savefig('mcmc_linear.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce608197-ac30-4545-9a32-40158b07910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1, 7):\n",
    "#     display(Math(samples1.getInlineLatex(str(i),limit=1)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9509ffb-59c4-4675-997a-41bcf6995ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fit_full = pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/full_data_set_mcmc/ext.fits\")[1].data).iloc[:, 1:13].T\n",
    "data_fit_void = np.array(data_fit_full)\n",
    "data_fit = []\n",
    "for item in data_fit_void:\n",
    "    arr= np.array(item)\n",
    "    data_fit.append(np.asarray(arr.tolist()))\n",
    "\n",
    "names = [\n",
    "    '1',\n",
    "    '2',\n",
    "    '3',\n",
    "    '4',\n",
    "    '5',\n",
    "    '6',\n",
    "    '7',\n",
    "    '8',\n",
    "    '9',\n",
    "    '10',\n",
    "    '11',\n",
    "    '12'\n",
    "]\n",
    "labels=[r\"\\mu_0\", r\"\\mu_{M1}\", r\"\\mu_{M2}\", r\"\\mu_{Z1}\",r\" \\mu_{Z2}\", r\"\\mu_{MZ}\", r\"\\sigma_0\", r\"\\sigma_{M1}\", r\"\\sigma_{M2}\", r\"\\sigma_{Z1}\", r\"\\sigma_{Z2}\", r\"\\sigma_{MZ}\" ]\n",
    "settings = {\n",
    "    \"mult_bias_correction_order\": 0,\n",
    "    \"smooth_scale_2D\": 3,\n",
    "    \"smooth_scale_1D\": 3,\n",
    "    \"boundary_correction_order\": 0,\n",
    "}\n",
    "samples2 = MCSamples(samples=data_fit, names=names, labels=labels, settings=settings)\n",
    "samples2.removeBurn(0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5651a92-67ba-49a8-b351-321cfdc3799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triangle plot\n",
    "g2 = plots.get_subplot_plotter()\n",
    "\n",
    "g2.settings.lab_fontsize = 40\n",
    "g2.settings.legend_fontsize = 40\n",
    "g2.settings.axes_fontsize = 30\n",
    "\n",
    "g2.triangle_plot(\n",
    "    [samples2],\n",
    "    filled=True,\n",
    "    contour_ls=\"-\",\n",
    "    contour_lws=1,\n",
    "    fine_bins=1,\n",
    "    colors=['#b186f1'],\n",
    "    fontsize=70,\n",
    "    line_args=[{'lw':1.2,'ls':'-', 'color':'#b186f1'}],\n",
    "    legend_labels=[\"Estendido\", ],\n",
    ")\n",
    "#plt.savefig('mcmc.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee06f31-668b-435f-989b-753bb5952805",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 13):\n",
    "    display(Math(samples2.getInlineLatex(str(i),limit=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed6959-fe54-4cfc-81c4-34e9e4096fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_fit_full = pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/full_data_set_mcmc/asc.fits\")[1].data).iloc[:, 1:7].T\n",
    "data_fit_full = pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/full_data_set_mcmc/asc_without_corretion.fits\")[1].data).iloc[:, 1:7].T\n",
    "data_fit_void = np.array(data_fit_full)\n",
    "data_fit = []\n",
    "for item in data_fit_void:\n",
    "    arr= np.array(item)\n",
    "    data_fit.append(np.asarray(arr.tolist()))\n",
    "\n",
    "names = [\n",
    "    '1',\n",
    "    '2',\n",
    "    '3',\n",
    "    '4',\n",
    "    '5',\n",
    "    '6',\n",
    "]\n",
    "labels=[r\"\\mu_{0}\", r\"\\mu_{1}\", r\"\\mu_{2}\", r\"\\sigma_{0}\", r\"\\sigma_{1}\", r\"\\sigma_{2}\"]\n",
    "settings = {\n",
    "    \"mult_bias_correction_order\": 0,\n",
    "    \"smooth_scale_2D\": 3,\n",
    "    \"smooth_scale_1D\": 3,\n",
    "    \"boundary_correction_order\": 0,\n",
    "}\n",
    "samples1 = MCSamples(samples=data_fit, names=names, labels=labels, settings=settings)\n",
    "samples1.removeBurn(0.3)\n",
    "\n",
    "print(samples1.get1DDensity(1).getLimits(0.68)[0], samples1.get1DDensity(1).getLimits(0.68)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862e309-e16a-4071-b9b9-c5c5aec64136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def confidence_region_1d(x, level=0.683):\n",
    "#     x_sorted = np.sort(x)\n",
    "#     n = len(x_sorted)\n",
    "#     ci_index = int(np.floor(level * n))\n",
    "#     width = x_sorted[ci_index:] - x_sorted[:n - ci_index]\n",
    "#     min_idx = np.argmin(width)\n",
    "#     return x_sorted[min_idx], x_sorted[min_idx + ci_index]\n",
    "\n",
    "# sample = np.random.normal(loc=0, scale=1, size=10000)\n",
    "\n",
    "# level = 0.683\n",
    "# lower, upper = confidence_region_1d(sample, level=level)\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.hist(sample, bins=50, density=True, alpha=0.6, color='gray')\n",
    "# plt.axvline(lower, color='red', linestyle='--', label=f'{level*100:.1f}% CI')\n",
    "# plt.axvline(upper, color='red', linestyle='--')\n",
    "# plt.title(f'Histogram with {level*100:.1f}% Confidence Region')\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('Density')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b497c8-b662-4095-95dc-c43860cb3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fit_5  = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/without_correction/asc_rmin_5_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "data_fit_10 = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/without_correction/asc_rmin_10_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "data_fit_20 = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/without_correction/asc_rmin_15_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "data_fit_30 = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/without_correction/asc_rmin_20_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "\n",
    "data_fit_void_5  = np.array(data_fit_5)\n",
    "data_fit_void_10 = np.array(data_fit_10)\n",
    "data_fit_void_20 = np.array(data_fit_20)\n",
    "data_fit_void_30 = np.array(data_fit_30)\n",
    "\n",
    "data_fit = []\n",
    "for item in data_fit_void_5:\n",
    "    arr = np.array(item)\n",
    "    data_fit.append(np.asarray(arr.tolist()))\n",
    "\n",
    "data_fit_2 = []\n",
    "for item in data_fit_void_10:\n",
    "    arr = np.array(item)\n",
    "    data_fit_2.append(np.asarray(arr.tolist()))\n",
    "\n",
    "data_fit_3 = []\n",
    "for item in data_fit_void_20:\n",
    "    arr = np.array(item)\n",
    "    data_fit_3.append(np.asarray(arr.tolist()))\n",
    "\n",
    "data_fit_4 = []\n",
    "for item in data_fit_void_30:\n",
    "    arr = np.array(item)\n",
    "    data_fit_4.append(np.asarray(arr.tolist()))\n",
    "\n",
    "names = ['1','2','3','4','5','6',]\n",
    "labels = [r\"\\mu_0\", r\"\\mu_{M1}\" ,r\"\\mu_{Z1}\",r\"\\sigma_0\", r\"\\sigma_{M1}\", r\"\\sigma_{Z1}\"]\n",
    "\n",
    "settings = {\n",
    "    \"mult_bias_correction_order\": 0,\n",
    "    \"smooth_scale_2D\": 3,\n",
    "    \"smooth_scale_1D\": 3,\n",
    "    \"boundary_correction_order\": 0,\n",
    "}\n",
    "samples_5  = MCSamples(samples=data_fit, names=names, labels=labels, settings=settings)\n",
    "samples_10 = MCSamples(samples=data_fit_2, names=names, labels=labels, settings=settings)\n",
    "samples_20 = MCSamples(samples=data_fit_3, names=names, labels=labels, settings=settings)\n",
    "samples_30 = MCSamples(samples=data_fit_4, names=names, labels=labels, settings=settings)\n",
    "\n",
    "bf = [4.04, 1.053, 0.2138,  0.5003, -0.02672, -0.1495]\n",
    "\n",
    "samples_5.removeBurn(0.3)\n",
    "samples_10.removeBurn(0.3)\n",
    "samples_20.removeBurn(0.3)\n",
    "samples_30.removeBurn(0.3)\n",
    "\n",
    "# Triangle plot\n",
    "g2 = plots.get_subplot_plotter()\n",
    "g2.triangle_plot(\n",
    "    [samples_30, samples_20, samples_10, samples_5],\n",
    "    filled=True,\n",
    "    contour_ls=\"-\",\n",
    "    contour_lws=1,\n",
    "    fine_bins=1,\n",
    "    # colors=[\"blue\" , \"red\", \"green\", \"purple\"],\n",
    "    fontsize=70,\n",
    "    line_args=[{\"lw\": 1.2, \"ls\": \"-\", \"color\": \"#b186f1\"}],\n",
    "    legend_labels=[\n",
    "        r\"$\\lambda_{cut} =20.0$\",r\"$\\lambda_{cut} =15.0$\",r\"$\\lambda_{cut} =10.0$\",r\"$\\lambda_{cut} =5.0$\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "for i, param1 in enumerate(names):\n",
    "    for j, param2 in enumerate(names):\n",
    "        if i == j:\n",
    "            g2.subplots[i, j].axvline(\n",
    "                bf[i], color=\"orange\" ,linestyle=\"--\", label=\"Best Fit\"\n",
    "            )\n",
    "        elif i > j:\n",
    "            g2.subplots[i, j].axvline(bf[j], color=\"orange\", linestyle=\"--\")\n",
    "            g2.subplots[i, j].axhline(bf[i], color=\"orange\", linestyle=\"--\")\n",
    "\n",
    "\n",
    "plt.savefig(\"mc_corner_plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d5949-8446-47ad-945e-1411eb9da3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fit_5  = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/with_correction/asc_rmin_5_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "data_fit_10 = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/with_correction/asc_rmin_10_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "data_fit_15 = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/with_correction/asc_rmin_15_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "data_fit_20 = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/with_correction/asc_rmin_20_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "# data_fit_30 = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/with_correction/asc_rmin_30_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "# data_fit_40 = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/with_correction/asc_rmin_40_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "\n",
    "\n",
    "data_fit_void_5  = np.array(data_fit_5)\n",
    "data_fit_void_10 = np.array(data_fit_10)\n",
    "data_fit_void_15 = np.array(data_fit_15)\n",
    "data_fit_void_20 = np.array(data_fit_20)\n",
    "# data_fit_void_30 = np.array(data_fit_30)\n",
    "# data_fit_void_40 = np.array(data_fit_40)\n",
    "\n",
    "data_fit = []\n",
    "for item in data_fit_void_5:\n",
    "    arr = np.array(item)\n",
    "    data_fit.append(np.asarray(arr.tolist()))\n",
    "\n",
    "data_fit_2 = []\n",
    "for item in data_fit_void_10:\n",
    "    arr = np.array(item)\n",
    "    data_fit_2.append(np.asarray(arr.tolist()))\n",
    "\n",
    "data_fit_3 = []\n",
    "for item in data_fit_void_15:\n",
    "    arr = np.array(item)\n",
    "    data_fit_3.append(np.asarray(arr.tolist()))\n",
    "\n",
    "data_fit_4 = []\n",
    "for item in data_fit_void_20:\n",
    "    arr = np.array(item)\n",
    "    data_fit_4.append(np.asarray(arr.tolist()))\n",
    "\n",
    "# data_fit_5 = []\n",
    "# for item in data_fit_void_30:\n",
    "#     arr = np.array(item)\n",
    "#     data_fit_5.append(np.asarray(arr.tolist()))\n",
    "\n",
    "# data_fit_6 = []\n",
    "# for item in data_fit_void_40:\n",
    "#     arr = np.array(item)\n",
    "#     data_fit_6.append(np.asarray(arr.tolist()))\n",
    "\n",
    "names = ['1','2','3','4','5','6',]\n",
    "labels = [r\"\\mu_0\", r\"\\mu_{M1}\" ,r\"\\mu_{Z1}\",r\"\\sigma_0\", r\"\\sigma_{M1}\", r\"\\sigma_{Z1}\"]\n",
    "\n",
    "settings = {\n",
    "    \"mult_bias_correction_order\": 0,\n",
    "    \"smooth_scale_2D\": 3,\n",
    "    \"smooth_scale_1D\": 3,\n",
    "    \"boundary_correction_order\": 0,\n",
    "}\n",
    "samples_5  = MCSamples(samples=data_fit, names=names, labels=labels, settings=settings)\n",
    "samples_10 = MCSamples(samples=data_fit_2, names=names, labels=labels, settings=settings)\n",
    "samples_15 = MCSamples(samples=data_fit_3, names=names, labels=labels, settings=settings)\n",
    "samples_20 = MCSamples(samples=data_fit_4, names=names, labels=labels, settings=settings)\n",
    "# samples_30 = MCSamples(samples=data_fit_5, names=names, labels=labels, settings=settings)\n",
    "# samples_40 = MCSamples(samples=data_fit_6, names=names, labels=labels, settings=settings)\n",
    "\n",
    "bf = list(samples_5.getMeans())\n",
    "      \n",
    "samples_5.removeBurn(0.3)\n",
    "samples_10.removeBurn(0.3)\n",
    "samples_15.removeBurn(0.3)\n",
    "samples_20.removeBurn(0.3)\n",
    "# samples_30.removeBurn(0.3)\n",
    "# samples_40.removeBurn(0.3)\n",
    "# r\"$\\lambda_{cut} =40.0$\", r\"$\\lambda_{cut} =30.0$\"\n",
    "\n",
    "#samples_40, samples_30,\n",
    "# Triangle plot\n",
    "g2 = plots.get_subplot_plotter()\n",
    "g2.triangle_plot(\n",
    "    [samples_20, samples_15, samples_10, samples_5],\n",
    "    filled=True,\n",
    "    contour_ls=\"-\",\n",
    "    contour_lws=1,\n",
    "    fine_bins=1,\n",
    "    # colors=[\"blue\" , \"red\", \"green\", \"purple\", \"yellow\", \"black\"],\n",
    "    fontsize=70,\n",
    "    line_args=[{\"lw\": 1.2, \"ls\": \"-\", \"color\": \"#b186f1\"}],\n",
    "    legend_labels=[\n",
    "        r\"$\\lambda_{cut} =20.0$\",r\"$\\lambda_{cut} =15.0$\",r\"$\\lambda_{cut} =10.0$\",r\"$\\lambda_{cut} =5.0$\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "for i, param1 in enumerate(names):\n",
    "    for j, param2 in enumerate(names):\n",
    "        if i == j:\n",
    "            g2.subplots[i, j].axvline(\n",
    "                bf[i], color=\"orange\" ,linestyle=\"--\", label=\"Best Fit\"\n",
    "            )\n",
    "        elif i > j:\n",
    "            g2.subplots[i, j].axvline(bf[j], color=\"orange\", linestyle=\"--\")\n",
    "            g2.subplots[i, j].axhline(bf[i], color=\"orange\", linestyle=\"--\")\n",
    "\n",
    "\n",
    "plt.savefig(\"mc_corner_plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db985bd6-069b-40e1-b87a-f8ad4c310665",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fit_5  = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/without_correction/asc_rmin_5_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "data_fit_10 = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/without_correction/asc_rmin_10_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "data_fit_15 = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/without_correction/asc_rmin_15_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "data_fit_20 = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/without_correction/asc_rmin_20_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "# data_fit_30 = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/without_correction/asc_rmin_30_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "# data_fit_40 = (pd.DataFrame(fits.open(\"/global/homes/c/cinlima/ESMCMC/without_correction/asc_rmin_40_mmin_100000000000000.fits\")[1].data).iloc[:, 1:7].T)\n",
    "\n",
    "data_fit_void_5  = np.array(data_fit_5)\n",
    "data_fit_void_10 = np.array(data_fit_10)\n",
    "data_fit_void_15 = np.array(data_fit_15)\n",
    "data_fit_void_20 = np.array(data_fit_20)\n",
    "# data_fit_void_30 = np.array(data_fit_30)\n",
    "# data_fit_void_40 = np.array(data_fit_40)\n",
    "\n",
    "data_fit = []\n",
    "for item in data_fit_void_5:\n",
    "    arr = np.array(item)\n",
    "    data_fit.append(np.asarray(arr.tolist()))\n",
    "\n",
    "data_fit_2 = []\n",
    "for item in data_fit_void_10:\n",
    "    arr = np.array(item)\n",
    "    data_fit_2.append(np.asarray(arr.tolist()))\n",
    "\n",
    "data_fit_3 = []\n",
    "for item in data_fit_void_15:\n",
    "    arr = np.array(item)\n",
    "    data_fit_3.append(np.asarray(arr.tolist()))\n",
    "\n",
    "data_fit_4 = []\n",
    "for item in data_fit_void_20:\n",
    "    arr = np.array(item)\n",
    "    data_fit_4.append(np.asarray(arr.tolist()))\n",
    "\n",
    "# data_fit_5 = []\n",
    "# for item in data_fit_void_30:\n",
    "#     arr = np.array(item)\n",
    "#     data_fit_5.append(np.asarray(arr.tolist()))\n",
    "\n",
    "# data_fit_6 = []\n",
    "# for item in data_fit_void_40:\n",
    "#     arr = np.array(item)\n",
    "#     data_fit_6.append(np.asarray(arr.tolist()))\n",
    "\n",
    "names = ['1','2','3','4','5','6',]\n",
    "labels = [r\"\\mu_0\", r\"\\mu_{M1}\" ,r\"\\mu_{Z1}\",r\"\\sigma_0\", r\"\\sigma_{M1}\", r\"\\sigma_{Z1}\"]\n",
    "\n",
    "settings = {\n",
    "    \"mult_bias_correction_order\": 0,\n",
    "    \"smooth_scale_2D\": 3,\n",
    "    \"smooth_scale_1D\": 3,\n",
    "    \"boundary_correction_order\": 0,\n",
    "}\n",
    "samples_5  = MCSamples(samples=data_fit, names=names, labels=labels, settings=settings)\n",
    "samples_10 = MCSamples(samples=data_fit_2, names=names, labels=labels, settings=settings)\n",
    "samples_15 = MCSamples(samples=data_fit_3, names=names, labels=labels, settings=settings)\n",
    "samples_20 = MCSamples(samples=data_fit_4, names=names, labels=labels, settings=settings)\n",
    "# samples_30 = MCSamples(samples=data_fit_5, names=names, labels=labels, settings=settings)\n",
    "# samples_40 = MCSamples(samples=data_fit_6, names=names, labels=labels, settings=settings)\n",
    "\n",
    "bf = list(samples_5.getMeans())\n",
    "\n",
    "samples_5.removeBurn(0.3)\n",
    "samples_10.removeBurn(0.3)\n",
    "samples_15.removeBurn(0.3)\n",
    "samples_20.removeBurn(0.3)\n",
    "# samples_30.removeBurn(0.3)\n",
    "# samples_40.removeBurn(0.3)\n",
    "\n",
    "# samples_40, samples_30,\n",
    "# Triangle plot\n",
    "g2 = plots.get_subplot_plotter()\n",
    "g2.triangle_plot(\n",
    "    [samples_20, samples_15, samples_10, samples_5],\n",
    "    filled=True,\n",
    "    contour_ls=\"-\",\n",
    "    contour_lws=1,\n",
    "    fine_bins=1,\n",
    "    # colors=[\"blue\" , \"red\", \"green\", \"purple\", \"yellow\", \"black\"],\n",
    "    fontsize=70,\n",
    "    line_args=[{\"lw\": 1.2, \"ls\": \"-\", \"color\": \"#b186f1\"}],\n",
    "    legend_labels=[\n",
    "        r\"$\\lambda_{cut} =20.0$\",r\"$\\lambda_{cut} =15.0$\",r\"$\\lambda_{cut} =10.0$\",r\"$\\lambda_{cut} =5.0$\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "#r\"$\\lambda_{cut} =40.0$\", r\"$\\lambda_{cut} =30.0$\",\n",
    "for i, param1 in enumerate(names):\n",
    "    for j, param2 in enumerate(names):\n",
    "        if i == j:\n",
    "            g2.subplots[i, j].axvline(\n",
    "                bf[i], color=\"orange\" ,linestyle=\"--\", label=\"Best Fit\"\n",
    "            )\n",
    "        elif i > j:\n",
    "            g2.subplots[i, j].axvline(bf[j], color=\"orange\", linestyle=\"--\")\n",
    "            g2.subplots[i, j].axhline(bf[i], color=\"orange\", linestyle=\"--\")\n",
    "\n",
    "\n",
    "plt.savefig(\"mc_corner_plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c339e-bf84-4dfc-ad08-c5fd01ea7486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numcosmo",
   "language": "python",
   "name": "numcosmo_developer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
