{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a519124-8e0e-41e4-a63f-0ecc103caef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "try:\n",
    "    import gi\n",
    "\n",
    "    gi.require_version(\"NumCosmo\", \"1.0\")\n",
    "    gi.require_version(\"NumCosmoMath\", \"1.0\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from gi.repository import GObject\n",
    "from gi.repository import NumCosmo as Nc\n",
    "from gi.repository import NumCosmoMath as Ncm\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../scripts\")\n",
    "\n",
    "import pyccl as ccl\n",
    "from nc_ccl import create_nc_obj, ccl_cosmo_set_high_prec\n",
    "\n",
    "Ncm.cfg_init()\n",
    "Ncm.cfg_set_log_handler(lambda msg: sys.stdout.write(msg) and sys.stdout.flush())\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import scipy.integrate\n",
    "import astropy.units as u\n",
    "import GCRCatalogs\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "catalog = \"skysim5000_v1.1.1\"\n",
    "skysim_cat = GCRCatalogs.load_catalog(catalog)\n",
    "cosmo_ss = skysim_cat.cosmology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f10294-9a67-4afd-8129-13d32a2a16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo = Nc.HICosmoDEXcdm()\n",
    "reion = Nc.HIReionCamb.new()\n",
    "prim = Nc.HIPrimPowerLaw.new()\n",
    "\n",
    "cosmo.add_submodel(reion)\n",
    "cosmo.add_submodel(prim)\n",
    "\n",
    "dist = Nc.Distance.new(2.0)\n",
    "\n",
    "tf = Nc.TransferFunc.new_from_name(\"NcTransferFuncEH\")\n",
    "\n",
    "psml = Nc.PowspecMLTransfer.new(tf)\n",
    "\n",
    "# psml = Nc.PowspecMLCBE.new ()\n",
    "psml.require_kmin(1.0e-6)\n",
    "psml.require_kmax(1.0e3)\n",
    "\n",
    "psf = Ncm.PowspecFilter.new(psml, Ncm.PowspecFilterType.TOPHAT)\n",
    "psf.set_best_lnr0()\n",
    "\n",
    "\n",
    "cosmo.props.H0 = cosmo_ss.H0.value\n",
    "cosmo.props.Omegab = cosmo_ss.Ob0\n",
    "cosmo.props.Omegac = cosmo_ss.Odm0\n",
    "cosmo.props.Omegax = cosmo_ss.Ode0\n",
    "\n",
    "cosmo.omega_x2omega_k()\n",
    "cosmo.param_set_by_name(\"Omegak\", 0.0)\n",
    "\n",
    "prim.props.n_SA = cosmo_ss.n_s\n",
    "print(cosmo_ss.sigma8, cosmo.sigma8(psf), cosmo.Omega_k0())\n",
    "\n",
    "old_amplitude = math.exp(prim.props.ln10e10ASA)\n",
    "prim.props.ln10e10ASA = math.log(\n",
    "    (cosmo_ss.sigma8 / cosmo.sigma8(psf)) ** 2 * old_amplitude\n",
    ")\n",
    "print(cosmo_ss.sigma8, cosmo.sigma8(psf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18891399-fce5-436b-addc-0b0272f498bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CosmoSim_proxy model\n",
    "# M_0, z_0\n",
    "theta_pivot = [3e14 / 0.71, 0.6]\n",
    "# \\mu_0, a_\\mu^z, a_\\mu^M\n",
    "theta_mu = [3.19, -0.7, 2]\n",
    "# \\sigma_0, a_\\sigma^z, a_\\sigma^M\n",
    "theta_sigma = [0.33, 0.0, -0.08]\n",
    "# Richness object\n",
    "\n",
    "area = 439.78987\n",
    "lnRl = 0.0\n",
    "lnRu = 2.0\n",
    "zl = 0.0\n",
    "zu = 1.0\n",
    "\n",
    "# Numcosmo_proxy model\n",
    "cluster_z = Nc.ClusterRedshift.new_from_name(\n",
    "    \"NcClusterRedshiftNodist{'z-min': <%20.15e>, 'z-max':<%20.15e>}\" % (zl, zu)\n",
    ")\n",
    "\n",
    "cluster_m = Nc.ClusterMass.new_from_name(\n",
    "    \"NcClusterMassAscaso{'M0':<%20.15e>,'z0':<%20.15e>,'lnRichness-min':<%20.15e>, 'lnRichness-max':<%20.15e>}\"\n",
    "    % (3e14 / (0.71), 0.6, lnRl, lnRu)\n",
    ")\n",
    "cluster_m.param_set_by_name(\"mup0\", 3.19)\n",
    "cluster_m.param_set_by_name(\"mup1\", 2 / np.log(10))\n",
    "cluster_m.param_set_by_name(\"mup2\", -0.7 / np.log(10))\n",
    "cluster_m.param_set_by_name(\"sigmap0\", 0.33)\n",
    "cluster_m.param_set_by_name(\"sigmap1\", -0.08 / np.log(10))\n",
    "cluster_m.param_set_by_name(\"sigmap2\", 0 / np.log(10))\n",
    "\n",
    "# Nodist\n",
    "\n",
    "# cluster_m = Nc.ClusterMass.new_from_name(\"NcClusterMassNodist{'lnM-min':<%20.15e>, 'lnM-max':<%20.15e>}\" % (math.log(10)*np.log10(1e13),math.log(10)*np.log10(1e15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e9ecd4-0911-4972-8deb-4b35d11aa740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numcosmo Cluster Abundance\n",
    "\n",
    "# First we need to define the multiplicity function here we will use the tinker\n",
    "mulf = Nc.MultiplicityFuncTinker.new()\n",
    "mulf.set_linear_interp(True)\n",
    "mulf.set_mdef(Nc.MultiplicityFuncMassDef.CRITICAL)\n",
    "mulf.set_Delta(200)\n",
    "# Second we need to construct a filtered power spectrum\n",
    "\n",
    "hmf = Nc.HaloMassFunction.new(dist, psf, mulf)\n",
    "hmf.set_area_sd(area)\n",
    "\n",
    "ca = Nc.ClusterAbundance.new(hmf, None)\n",
    "mset = Ncm.MSet.new_array([cosmo, cluster_m, cluster_z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aa258c-8563-471d-8712-bd81d097b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With proxy\n",
    "\n",
    "ncount = Nc.DataClusterNCount.new(ca, \"NcClusterRedshiftNodist\", \"NcClusterMassAscaso\")\n",
    "ncount.catalog_load(\"ncount_ascaso2.fits\")\n",
    "\n",
    "# True table\n",
    "\n",
    "# ncount = Nc.DataClusterNCount.new (ca, \"NcClusterRedshiftNodist\", \"NcClusterMassNodist\")\n",
    "# ncount.catalog_load (\"ncount_nodist.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cf6f84-b9eb-4beb-ac53-e421aef6c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo.props.Omegac_fit = True\n",
    "prim.props.ln10e10ASA_fit = True\n",
    "\n",
    "cluster_m.props.mup0_fit = True\n",
    "\"\"\"\n",
    "cluster_m.props.mup1_fit = True\n",
    "cluster_m.props.mup2_fit = True\n",
    "cluster_m.props.sigmap0_fit = True\n",
    "cluster_m.props.sigmap1_fit = True\n",
    "cluster_m.props.sigmap2_fit = True\n",
    "\"\"\"\n",
    "\n",
    "mset.prepare_fparam_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f9cbc-a199-4c47-b29f-20e9705bd7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncount.set_binned(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9ce161-5be9-496d-a652-4b774ffb8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = Ncm.Dataset.new()\n",
    "dset.append_data(ncount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8cd3ba-f138-4c7b-8cf5-b7ce74bc82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh = Ncm.Likelihood(dataset=dset)\n",
    "fit = Ncm.Fit.new(\n",
    "    Ncm.FitType.NLOPT, \"ln-neldermead\", lh, mset, Ncm.FitGradType.NUMDIFF_FORWARD\n",
    ")\n",
    "fit.log_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c3b17-1ea3-4fd4-8497-f134c913f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Setting single thread calculation.\n",
    "#\n",
    "Ncm.func_eval_set_max_threads(150)\n",
    "Ncm.func_eval_log_pool_stats()\n",
    "\n",
    "#\n",
    "# Additional functions as we want the chains for sigma8 and Omegam, which are derived parameters\n",
    "#\n",
    "mfunc_oa = Ncm.ObjArray.new()\n",
    "\n",
    "mfunc_Omegam = Ncm.MSetFuncList.new(\"NcHICosmo:Omega_m0\", None)\n",
    "mfunc_sigma8 = Ncm.MSetFuncList.new(\"NcHICosmo:sigma8\", psf)\n",
    "\n",
    "\n",
    "mfunc_oa.add(mfunc_sigma8)\n",
    "mfunc_oa.add(mfunc_Omegam)\n",
    "\n",
    "print(mfunc_sigma8.eval0(mset))\n",
    "print(mfunc_Omegam.eval0(mset))\n",
    "\n",
    "#\n",
    "# New Gaussian prior to provide the initial points for the chain.\n",
    "# It was created with size 0 (number of parameters), but once\n",
    "# initialized with mset the correct size is assigned.\n",
    "#\n",
    "# The initial sampler will use a diagonal covariance with the\n",
    "# diagonal terms being the parameters scale set by each model.\n",
    "#\n",
    "init_sampler = Ncm.MSetTransKernGauss.new(0)\n",
    "init_sampler.set_mset(mset)\n",
    "init_sampler.set_prior_from_mset()\n",
    "init_sampler.set_cov_from_rescale(1.0)  # 1\n",
    "\n",
    "#\n",
    "# Creates the ESMCMC walker object, this object is responsible\n",
    "# for moving the walkers in each interation, the stretch move\n",
    "# is affine invariant and therefore gives good results even for\n",
    "# very correlated parametric space.\n",
    "#\n",
    "sampler = \"apes\"\n",
    "# sampler  = 'stretch'\n",
    "nwalkers = int(math.ceil(500))  # 500\n",
    "ssize = 15000  # 1000000\n",
    "\n",
    "if sampler == \"apes\":\n",
    "    walker = Ncm.FitESMCMCWalkerAPES.new(nwalkers, mset.fparams_len())\n",
    "elif sampler == \"stretch\":\n",
    "    walker = Ncm.FitESMCMCWalkerStretch.new(nwalkers, mset.fparams_len())\n",
    "#\n",
    "# The methods below set the walk scale, which controls the size of the\n",
    "# step done between two walkers and circumscribe the walkers inside\n",
    "# the box defined by the parameters inside the mset object.\n",
    "#\n",
    "# walker.set_scale (3.0)\n",
    "# walker.set_box_mset (mset)\n",
    "#\n",
    "# Initialize the ESMCMC object using the objects above. It will\n",
    "# use 50 walkers, i.e., each point in the MCMC chain contains\n",
    "# 50 points in the parametric space. Each step uses the last point\n",
    "# in the chain (the last 50 parametric points) to calculate the\n",
    "# proposal points.\n",
    "#\n",
    "esmcmc = Ncm.FitESMCMC.new_funcs_array(\n",
    "    fit, nwalkers, init_sampler, walker, Ncm.FitRunMsgs.SIMPLE, mfunc_oa\n",
    ")\n",
    "\n",
    "#\n",
    "# These methods enable the auto-trim options on ESMCMC. This option\n",
    "# makes the sampler check the chains' health and trim any unnecessary\n",
    "# burn-in part. We set the number of divisions to 100 so we test the\n",
    "# chains in blocks of n/100. The last method asserts that each 2min\n",
    "# the catalog will be checked.\n",
    "#\n",
    "# esmcmc.set_auto_trim (True)\n",
    "# esmcmc.set_auto_trim_div (100)\n",
    "# esmcmc.set_max_runs_time (2.0 * 60.0)\n",
    "# esmcmc.set_nthreads (4)\n",
    "\n",
    "# With self calibration\n",
    "esmcmc.set_data_file(\"mcmc_ascaso_binned.fits\")\n",
    "# without self calibration\n",
    "# esmcmc.set_data_file (\"mcmc_ascaso_binned_noself.fits\")\n",
    "# esmcmc.set_data_file (\"mcmc_nodist_binned.fits\")\n",
    "\n",
    "esmcmc.set_nthreads(150)\n",
    "\n",
    "#\n",
    "# Running the esmcmc, it will first calculate 1000 points, after that\n",
    "# it will estimate the error in the parameters mean. Using the current\n",
    "# errors the algorithm tries to calculated how many extra steps are\n",
    "# necessary to obtain the required error `10^-3' in every parameters,\n",
    "# and it will run such extra steps. It will repeat this procedure\n",
    "# until it attains the required error in every parameter.\n",
    "#\n",
    "#\n",
    "\n",
    "esmcmc.start_run()\n",
    "# esmcmc.run (ssize / nwalkers)\n",
    "# esmcmc.run (10)\n",
    "esmcmc.run_lre(50, 1.0e-3)\n",
    "esmcmc.end_run()\n",
    "\n",
    "#\n",
    "# Calculates the parameter means and covariance and set it into\n",
    "# the fit object and then print.\n",
    "#\n",
    "esmcmc.mean_covar()\n",
    "fit.log_covar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5679ef-42f3-45e7-b430-9ab692ab28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntests = 100.0\n",
    "nwalkers = 500\n",
    "burnin = 30\n",
    "mcat = Ncm.MSetCatalog.new_from_file_ro(\"mcmc_nodist_binned.fits\", nwalkers * burnin)\n",
    "\n",
    "mcat.log_current_chain_stats()\n",
    "mcat.calc_max_ess_time(ntests, Ncm.FitRunMsgs.SIMPLE)\n",
    "mcat.calc_heidel_diag(ntests, 0.0, Ncm.FitRunMsgs.SIMPLE)\n",
    "\n",
    "mset.pretty_log()\n",
    "mcat.log_full_covar()\n",
    "mcat.log_current_stats()\n",
    "\n",
    "be, post_lnnorm_sd = mcat.get_post_lnnorm()\n",
    "lnevol, glnvol = mcat.get_post_lnvol(0.6827)\n",
    "\n",
    "Ncm.cfg_msg_sepa()\n",
    "print(\n",
    "    \"# Bayesian evidence:                                 % 22.15g +/- % 22.15g\"\n",
    "    % (be, post_lnnorm_sd)\n",
    ")\n",
    "print(\"# 1 sigma posterior volume:                          % 22.15g\" % lnevol)\n",
    "print(\"# 1 sigma posterior volume (Gaussian approximation): % 22.15g\" % glnvol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1a7e07-94b2-4bfe-9bcb-3c9a420ac982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proxy noself 14 min 30 segundos 1-sigma posterior volume -10.41\n",
    "# proxy self 42 min 58 segundos 1-sigma posterior volume -14.39\n",
    "# nodist 13 min 56 segundos 1-sigma posterior volume -10.83"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numcosmo",
   "language": "python",
   "name": "numcosmo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
