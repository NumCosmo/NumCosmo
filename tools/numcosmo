#!/usr/bin/env python3
#
# numcosmo
#
# Wed Feb 8 10:00:00 2023
# Copyright  2023  Sandro Dias Pinto Vitenti
# <vitenti@uel.br>
#
# numcosmo
# Copyright (C) 2023 Sandro Dias Pinto Vitenti <vitenti@uel.br>
#
# numcosmo is free software: you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# numcosmo is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
# See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program.  If not, see <http://www.gnu.org/licenses/>.

""" NumCosmo script to perform different tasks.
"""

import dataclasses
from typing import Optional, Annotated, Tuple
from pathlib import Path
import typer

from numcosmo_py import Ncm
from numcosmo_py.external.cosmosis import (
    convert_likelihoods,
    create_numcosmo_mapping,
    LinearMatterPowerSpectrum,
    NonLinearMatterPowerSpectrum,
)
from numcosmo_py.sampling import (
    check_runner_algorithm,
    FisherType,
    FitGradType,
    FitRunMessages,
    FitRunner,
    NcmFitLogger,
    set_ncm_console,
)

app = typer.Typer(no_args_is_help=True, help="NumCosmo command line interface.")
app_run = typer.Typer(no_args_is_help=True, help="Run different statistical analyses.")
app.add_typer(app_run, name="run")


@app.command(name="from-cosmosis")
def numcosmo_from_cosmosis(
    inifile: Annotated[Path, typer.Argument(help="Path to the Cosmosis ini file.")],
    *,
    outfile: Annotated[
        Optional[Path],
        typer.Option(
            help="Path to the output file, if not given,"
            " the input file name is used with the extension .yaml."
        ),
    ] = None,
    matter_ps: Annotated[
        LinearMatterPowerSpectrum,
        typer.Option(help="Matter power spectrum to use."),
    ] = LinearMatterPowerSpectrum.NONE.value,
    nonlin_matter_ps: Annotated[
        NonLinearMatterPowerSpectrum,
        typer.Option(help="Non-linear matter power spectrum to use."),
    ] = NonLinearMatterPowerSpectrum.NONE.value,
    distance_max_z: Annotated[
        float,
        typer.Option(help="Max distance to optimize distance computations", min=0.0),
    ] = 10.0,
):
    """Converts a Cosmosis ini file to a NumCosmo yaml file, containing
    the same information. The NumCosmo yaml file can be used to run the
    same likelihoods in NumCosmo.

    :param inifile: Path to the Cosmosis ini file.
    :param outfile: Path to the output file, if not given, the input file name
        is used with the extension .yaml.
    :param matter_ps: Matter power spectrum to use.
    :param nonlin_matter_ps: Non-linear matter power spectrum to use.
    :param distance_max_z: Max distance to optimize distance computations.
    """

    Ncm.cfg_init()

    if outfile is None:
        outfile = Path(inifile.stem + ".yaml")

    mapping = create_numcosmo_mapping(
        matter_ps=matter_ps,
        nonlin_matter_ps=nonlin_matter_ps,
        distance_max_z=distance_max_z,
    )

    model_builders, mset, likelihood = convert_likelihoods(inifile, mapping=mapping)

    builders_file = outfile.with_suffix(".builders.yaml")

    experiment = Ncm.ObjDictStr.new()
    experiment.add("likelihood", likelihood)
    experiment.add("model-set", mset)

    ser = Ncm.Serialize.new(Ncm.SerializeOpt.CLEAN_DUP)
    ser.dict_str_to_yaml_file(model_builders, builders_file.absolute().as_posix())
    ser.dict_str_to_yaml_file(experiment, outfile.absolute().as_posix())


@dataclasses.dataclass
class LoadExperiment:
    """Common block for commands that load an experiment."""

    experiment: Annotated[
        Path, typer.Argument(help="Path to the experiment file to fit.")
    ]
    starting_point: Annotated[
        Optional[Path],
        typer.Option(
            help=(
                "Path to the file containing the starting point for the fit. "
                "The output of a previous fit can be used."
            ),
        ),
    ] = None
    output: Annotated[
        Optional[Path],
        typer.Option(
            help="Path to the output file, if given, the computed results are written to"
            " this file, otherwise they are not saved."
        ),
    ] = None

    def __post_init__(self):
        ser = Ncm.Serialize.new(Ncm.SerializeOpt.CLEAN_DUP)

        builders_file = self.experiment.with_suffix(".builders.yaml")
        model_builders = ser.dict_str_from_yaml_file(
            builders_file.absolute().as_posix()
        )

        for model_builder_name in model_builders.keys():
            model_builder = model_builders.get(model_builder_name)
            model_builder.create()

        # We need to initialize NumCosmo after creating the model builders
        # this is necessary because when using MPI, the model builders
        # should be created in all processes before initializing NumCosmo.
        Ncm.cfg_init()
        console = set_ncm_console()

        experiment_objects = ser.dict_str_from_yaml_file(
            self.experiment.absolute().as_posix()
        )

        if experiment_objects.peek("likelihood") is None:
            raise RuntimeError("No likelihood found in experiment file")

        likelihood: Ncm.Likelihood = experiment_objects.get("likelihood")

        if experiment_objects.peek("model-set") is None:
            raise RuntimeError("No model-set found in experiment file")

        mset: Ncm.MSet = experiment_objects.get("model-set")
        mset.prepare_fparam_map()

        if self.starting_point is not None:
            if not self.starting_point.exists():
                raise RuntimeError(
                    f"Starting point file {self.starting_point} not found."
                )

            ser.reset(False)
            starting_dict = ser.dict_str_from_yaml_file(
                self.starting_point.absolute().as_posix()
            )
            if starting_dict.peek("model-set") is None:
                raise RuntimeError(
                    f"Starting point file {self.starting_point} does not contain "
                    f"a model-set."
                )
            saved_mset: Ncm.MSet = starting_dict.get("model-set")
            assert isinstance(saved_mset, Ncm.MSet)
            if not mset.cmp(saved_mset, True):
                raise RuntimeError(
                    f"Starting point file {self.starting_point} "
                    f"does not match experiment."
                )
            mset.param_set_mset(saved_mset)

        self.console = console
        self.likelihood = likelihood
        self.mset = mset

        if self.output is not None:
            if self.output.exists():
                ser.reset(False)
                self.output_dict = ser.dict_str_from_yaml_file(
                    self.output.absolute().as_posix()
                )
            else:
                self.output_dict = Ncm.ObjDictStr.new()

    def end_experiment(self):
        """Ends the experiment and writes the output file."""
        if self.output is not None:
            ser = Ncm.Serialize.new(Ncm.SerializeOpt.CLEAN_DUP)
            ser.dict_str_to_yaml_file(
                self.output_dict, self.output.absolute().as_posix()
            )


@app_run.command(
    name="theory-vector", help="Computes theory vectory for a given experiment."
)
@dataclasses.dataclass
class ComputeTheoryVector(LoadExperiment):
    """Computes theory vectory for a given experiment."""

    def __post_init__(self):
        super().__post_init__()

        dset: Ncm.Dataset = self.likelihood.peek_dataset()
        if not dset.has_mean_vector():
            raise RuntimeError("mean vector computation not supported by this dataset.")

        theory_vector = Ncm.Vector.new(dset.get_n())
        dset.mean_vector(self.mset, theory_vector)
        if self.output is not None:
            self.output_dict.add("theory-vector", theory_vector)
        else:
            self.console.print(theory_vector.dup_array())

        self.end_experiment()


@dataclasses.dataclass
class RunCommonOptions(LoadExperiment):
    """Common options for the run command."""

    runner: Annotated[
        FitRunner,
        typer.Option(
            help="Algorithm to use for the fit.",
        ),
    ] = FitRunner.NLOPT.value
    algorithm: Annotated[
        Optional[str],
        typer.Option(
            help="Algorithm to use for the fit.",
        ),
    ] = None
    grad_type: Annotated[
        FitGradType,
        typer.Option(
            help="Gradient type to use for the fit.",
        ),
    ] = FitGradType.NUMDIFF_FORWARD.value
    run_messages: Annotated[
        FitRunMessages,
        typer.Option(
            help="Verbosity level for the fit.",
        ),
    ] = FitRunMessages.SIMPLE.value

    def __post_init__(self):
        super().__post_init__()

        check_runner_algorithm(self.runner, self.algorithm)

        fit = Ncm.Fit.factory(
            self.runner.genum,
            self.algorithm,
            self.likelihood,
            self.mset,
            self.grad_type.genum,
        )
        fit.set_messages(self.run_messages.genum)

        fit_logger = NcmFitLogger(self.console)
        fit.set_logger(
            fit_logger.write_progress,
            fit_logger.update_progress,
            fit_logger.start_update,
            fit_logger.end_update,
        )
        self.fit = fit


@app_run.command(name="fit", help="Computes the best fit of the model to the data.")
@dataclasses.dataclass
class RunFit(RunCommonOptions):
    """Computes the best fit of the model to the data."""

    restart: Annotated[
        Optional[Tuple[float, float]],
        typer.Option(
            help=(
                "Restart the fit until the given the value of m2lnL varies less"
                " than the given tolerance (abstol, reltol)."
            ),
        ),
    ] = None

    def __post_init__(self):
        super().__post_init__()
        self.fit.log_info()

        if self.restart is None:
            self.fit.run(self.run_messages.genum)
        else:
            if self.restart[0] <= 0.0 and self.restart[1] <= 0.0:
                raise RuntimeError(f"Invalid tolerance for restart {self.restart}.")
            output_filename = (
                None
                if self.output is None
                else self.output.with_suffix(".tmp").absolute().as_posix()
            )
            self.fit.run_restart(
                self.run_messages.genum,
                self.restart[0],
                self.restart[1],
                None,
                output_filename,
            )

        if self.output is not None:
            self.output_dict.add("model-set", self.fit.peek_mset())

        self.end_experiment()


@app_run.command(
    name="test", help="Loads the experiment file and computes the likelihood once."
)
@dataclasses.dataclass
class RunTest(RunCommonOptions):
    """Loads the experiment file and computes the likelihood once."""

    def __post_init__(self):
        super().__post_init__()
        self.mset.param_set_all_ftype(Ncm.ParamType.FIXED)
        self.mset.prepare_fparam_map()
        self.fit.log_info()
        self.fit.run(FitRunMessages.SIMPLE.genum)


@app_run.command(
    name="fisher", help="Computes the Fisher matrix of the model to the data."
)
@dataclasses.dataclass
class RunFisher(RunCommonOptions):
    """Computes the Fisher matrix of the model to the data."""

    fisher_type: Annotated[
        FisherType,
        typer.Option(
            help="Type of Fisher matrix to compute.",
        ),
    ] = FisherType.OBSERVED.value

    def __post_init__(self):
        super().__post_init__()
        if self.fisher_type == FisherType.OBSERVED:
            self.fit.obs_fisher()
            self.fit.log_covar()
        elif self.fisher_type == FisherType.EXPECTED:
            self.fit.fisher()
            self.fit.log_covar()
        else:
            raise RuntimeError(f"Invalid Fisher type {self.fisher_type}.")

        if self.output is not None:
            self.output_dict.add("model-set", self.fit.peek_mset())
            self.output_dict.add("covariance", self.fit.get_covar())

        self.end_experiment()


@app_run.command(
    name="fisher-bias",
    help="Computes the Fisher matrix of the model to the data and the bias.",
)
@dataclasses.dataclass
class RunFisherBias(RunCommonOptions):
    """Computes the Fisher matrix of the model to the data and the bias."""

    theory_vector: Annotated[
        Optional[Path],
        typer.Option(
            help="Path to the theory vector file to compute the bias relative to."
        ),
    ] = None

    def __post_init__(self):
        super().__post_init__()

        if self.theory_vector is None:
            raise RuntimeError("No theory vector file given.")

        ser = Ncm.Serialize.new(Ncm.SerializeOpt.CLEAN_DUP)
        theory_vector_dict = ser.dict_str_from_yaml_file(
            self.theory_vector.absolute().as_posix()
        )

        dset = self.likelihood.peek_dataset()
        if not dset.has_mean_vector():
            raise RuntimeError(
                "mean vector computation not supported by this dataset, "
                "cannot compute bias."
            )

        theory_vector = theory_vector_dict.get("theory-vector")
        if not isinstance(theory_vector, Ncm.Vector):
            raise RuntimeError("Invalid theory vector file.")

        if theory_vector.len() != dset.get_n():
            raise RuntimeError(
                "Theory vector and dataset have different sizes, "
                "cannot compute bias."
            )

        delta_theta = self.fit.fisher_bias(theory_vector)

        if self.output is not None:
            self.output_dict.add("covariance", self.fit.get_covar())
            self.output_dict.add("delta-theta", delta_theta)
        else:
            self.console.print(delta_theta.dup_array())

        self.end_experiment()


if __name__ == "__main__":
    app()
